import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository } from 'typeorm';
import { CACHE_MANAGER } from '@nestjs/cache-manager';
import { Inject } from '@nestjs/common';
import { Cache } from 'cache-manager';
import { EventEmitter2 } from '@nestjs/event-emitter';
import * as moment from 'moment-timezone';
import { mean, median, standardDeviation, quantile } from 'simple-statistics';

import { InventoryTransaction } from '../../inventory/entities/inventory-transaction.entity';
import { Product } from '../../products/entities/product.entity';
import { MLModel } from '../entities/ml-model.entity';
import { TrainingJob } from '../entities/training-job.entity';

/**
 * PHASE 4.1.3: Training Job Management System ðŸŽ¯
 * 
 * Comprehensive job management system for ML training workflows.
 * Handles job scheduling, execution monitoring, queue management,
 * resource allocation, and job lifecycle coordination.
 */

export interface TrainingJobRequest {
  tenantId: string;
  jobConfiguration: JobConfiguration;
  schedulingOptions: SchedulingOptions;
  resourceRequirements: JobResourceRequirement;
  executionParameters: ExecutionParameters;
  monitoringConfig: JobMonitoringConfig;
  retryPolicy?: JobRetryPolicy;
  notificationSettings?: JobNotificationSettings;
  priorityLevel: 'low' | 'medium' | 'high' | 'critical' | 'urgent';
}

export interface JobConfiguration {
  jobId: string;
  jobName: string;
  jobType: JobType;
  jobDescription: string;
  trainingPipelineId: string;
  modelSpecifications: JobModelSpec[];
  datasetReferences: DatasetReference[];
  hyperparameterSpace?: HyperparameterSpace;
  experimentConfig?: JobExperimentConfig;
  dependencies: JobDependency[];
  tags: Record<string, string>;
}

export type JobType = 
  | 'single_model_training'     // Train one model
  | 'batch_model_training'      // Train multiple models
  | 'hyperparameter_optimization' // HPO job
  | 'cross_validation_training' // CV training job
  | 'ensemble_training'         // Ensemble model training
  | 'transfer_learning'         // Transfer learning job
  | 'federated_learning'        // Federated learning job
  | 'continuous_training'       // Continuous/online learning
  | 'model_retraining'          // Retrain existing model
  | 'pipeline_training'         // Full pipeline training
  | 'benchmark_training'        // Benchmark comparison
  | 'ablation_study';           // Ablation study job

export interface JobModelSpec {
  modelId: string;
  modelType: string;
  baselineModelId?: string;
  trainingObjective: TrainingObjective;
  evaluationMetrics: string[];
  trainingParameters: Record<string, any>;
  validationStrategy: ValidationStrategy;
  deploymentTarget?: DeploymentTarget;
}

export interface TrainingObjective {
  primaryMetric: string;
  optimizationDirection: 'maximize' | 'minimize';
  targetValue?: number;
  constraintMetrics?: ConstraintMetric[];
  businessObjective?: string;
}

export interface ConstraintMetric {
  metricName: string;
  constraint: 'less_than' | 'greater_than' | 'between' | 'equal_to';
  value: number | [number, number];
  weight: number;
}

export interface ValidationStrategy {
  strategyType: 'holdout' | 'cross_validation' | 'time_series' | 'bootstrap' | 'custom';
  parameters: Record<string, any>;
  validationSize: number;
  validationMetrics: string[];
}

export interface DeploymentTarget {
  environment: 'development' | 'staging' | 'production' | 'canary';
  deploymentStrategy: 'immediate' | 'manual' | 'approval_required' | 'conditional';
  rolloutPercentage?: number;
  monitoringPeriod?: number; // hours
}

export interface DatasetReference {
  datasetId: string;
  datasetName: string;
  datasetVersion: string;
  datasetLocation: string;
  datasetSize: number;
  datasetSchema: DatasetSchema;
  accessCredentials?: DatasetCredentials;
  preprocessing?: DatasetPreprocessing;
}

export interface DatasetSchema {
  features: FeatureSchema[];
  targetVariable: string;
  indexColumns: string[];
  timeColumn?: string;
  categoricalColumns: string[];
  numericalColumns: string[];
}

export interface FeatureSchema {
  featureName: string;
  featureType: 'numerical' | 'categorical' | 'datetime' | 'text' | 'binary';
  nullable: boolean;
  description?: string;
  validRange?: [number, number];
  categories?: string[];
}

export interface DatasetCredentials {
  credentialType: 'api_key' | 'oauth' | 'basic_auth' | 'certificate' | 'token';
  credentials: Record<string, string>;
  expirationDate?: Date;
}

export interface DatasetPreprocessing {
  cleaningSteps: PreprocessingStep[];
  transformationSteps: PreprocessingStep[];
  featureEngineering: FeatureEngineering[];
  validationRules: DataValidationRule[];
}

export interface PreprocessingStep {
  stepName: string;
  stepType: string;
  parameters: Record<string, any>;
  applyToColumns?: string[];
  condition?: string;
}

export interface FeatureEngineering {
  engineeringType: 'derived_feature' | 'aggregation' | 'encoding' | 'scaling' | 'selection';
  inputFeatures: string[];
  outputFeatures: string[];
  transformation: string;
  parameters: Record<string, any>;
}

export interface DataValidationRule {
  ruleName: string;
  ruleType: 'completeness' | 'validity' | 'accuracy' | 'consistency';
  condition: string;
  severity: 'error' | 'warning' | 'info';
  action: 'stop' | 'warn' | 'fix' | 'ignore';
}

export interface HyperparameterSpace {
  parameters: HyperparameterDefinition[];
  searchStrategy: SearchStrategy;
  optimizationBudget: OptimizationBudget;
  priorKnowledge?: PriorKnowledge[];
}

export interface HyperparameterDefinition {
  parameterName: string;
  parameterType: 'continuous' | 'discrete' | 'categorical' | 'ordinal';
  searchSpace: ParameterSearchSpace;
  importance: 'high' | 'medium' | 'low';
  interactions?: string[];
}

export interface ParameterSearchSpace {
  min?: number;
  max?: number;
  values?: any[];
  distribution?: 'uniform' | 'log_uniform' | 'normal' | 'log_normal';
  step?: number;
}

export interface SearchStrategy {
  strategyType: 'grid_search' | 'random_search' | 'bayesian_optimization' | 'evolutionary' | 'multi_armed_bandit';
  maxEvaluations: number;
  parallelEvaluations: number;
  earlyStoppingEnabled: boolean;
  acquisitionFunction?: string;
  explorationRate?: number;
}

export interface OptimizationBudget {
  budgetType: 'time_based' | 'evaluation_based' | 'cost_based' | 'hybrid';
  budgetValue: number;
  budgetUnit: string;
  budgetConstraints: BudgetConstraint[];
}

export interface BudgetConstraint {
  constraintType: 'max_time' | 'max_cost' | 'max_evaluations' | 'max_resources';
  value: number;
  unit: string;
  enforced: boolean;
}

export interface PriorKnowledge {
  parameterName: string;
  knowledgeType: 'optimal_range' | 'good_values' | 'bad_values' | 'correlation';
  knowledge: any;
  confidence: number;
  source: string;
}

export interface JobExperimentConfig {
  experimentName: string;
  experimentTags: Record<string, string>;
  trackingPlatform: 'mlflow' | 'wandb' | 'tensorboard' | 'custom';
  trackingConfig: TrackingConfig;
  comparisonBaseline?: string;
  ablationTargets?: string[];
}

export interface TrackingConfig {
  logLevel: 'minimal' | 'standard' | 'detailed' | 'comprehensive';
  logFrequency: 'epoch' | 'batch' | 'custom';
  artifactLogging: ArtifactLogging;
  metricLogging: MetricLogging;
  customLogging: CustomLogging[];
}

export interface ArtifactLogging {
  logModels: boolean;
  logDatasets: boolean;
  logPlots: boolean;
  logCheckpoints: boolean;
  compressionEnabled: boolean;
  retentionPolicy: string;
}

export interface MetricLogging {
  trainingMetrics: boolean;
  validationMetrics: boolean;
  systemMetrics: boolean;
  businessMetrics: boolean;
  customMetrics: boolean;
  aggregationMethods: string[];
}

export interface CustomLogging {
  loggerName: string;
  loggerType: string;
  loggerConfig: Record<string, any>;
  loggerFrequency: string;
}

export interface JobDependency {
  dependencyId: string;
  dependencyType: 'job_completion' | 'data_availability' | 'resource_availability' | 'time_based' | 'condition_based';
  dependencyTarget: string;
  waitCondition: WaitCondition;
  timeoutMinutes?: number;
  failureAction: 'fail' | 'skip' | 'wait' | 'fallback';
}

export interface WaitCondition {
  conditionType: 'status_equals' | 'metric_threshold' | 'file_exists' | 'custom';
  conditionValue: any;
  evaluationInterval: number; // seconds
  maxWaitTime: number; // minutes
}

export interface SchedulingOptions {
  schedulingMode: SchedulingMode;
  startTime?: Date;
  recurringSchedule?: RecurringSchedule;
  resourcePool?: string;
  queueName?: string;
  affinityRules?: AffinityRule[];
  preemptionPolicy?: PreemptionPolicy;
}

export type SchedulingMode = 
  | 'immediate'        // Start immediately
  | 'scheduled'        // Start at specific time
  | 'resource_aware'   // Start when resources available
  | 'dependency_aware' // Start when dependencies satisfied
  | 'cost_optimized'   // Start during low-cost periods
  | 'queue_based'      // Add to queue
  | 'adaptive';        // Adaptive scheduling

export interface RecurringSchedule {
  frequency: 'hourly' | 'daily' | 'weekly' | 'monthly' | 'custom';
  interval: number;
  cronExpression?: string;
  timezone: string;
  endDate?: Date;
  maxInstances?: number;
}

export interface AffinityRule {
  ruleType: 'node_affinity' | 'pod_affinity' | 'anti_affinity';
  targetSelector: Record<string, string>;
  weight: number;
  required: boolean;
}

export interface PreemptionPolicy {
  preemptible: boolean;
  preemptionPriority: number;
  gracePeriodSeconds: number;
  checkpointBeforePreemption: boolean;
  restartPolicy: 'always' | 'on_failure' | 'never';
}

export interface JobResourceRequirement {
  computeResources: JobComputeRequirement;
  memoryRequirement: JobMemoryRequirement;
  storageRequirement: JobStorageRequirement;
  networkRequirement: JobNetworkRequirement;
  specialResources?: SpecialResourceRequirement[];
  resourceConstraints: ResourceConstraint[];
}

export interface JobComputeRequirement {
  cpuCores: number;
  cpuType?: 'intel' | 'amd' | 'arm' | 'any';
  gpuRequired: boolean;
  gpuType?: 'nvidia' | 'amd' | 'intel' | 'any';
  gpuMemory?: number; // GB
  gpuCount?: number;
  tpuRequired?: boolean;
  computeIntensity: 'low' | 'medium' | 'high' | 'extreme';
}

export interface JobMemoryRequirement {
  ramRequired: number; // GB
  memoryType: 'standard' | 'high_bandwidth' | 'low_latency';
  swapEnabled: boolean;
  memoryOptimization: 'speed' | 'capacity' | 'balanced';
}

export interface JobStorageRequirement {
  diskSpace: number; // GB
  storageType: 'ssd' | 'nvme' | 'hdd' | 'network';
  iopsRequired: number;
  throughputRequired: number; // MB/s
  temporaryStorage: number; // GB
  persistentStorage: number; // GB
}

export interface JobNetworkRequirement {
  bandwidthRequired: number; // Mbps
  latencyThreshold: number; // ms
  networkType: 'standard' | 'high_performance' | 'low_latency';
  externalAccess: boolean;
  dataTransferVolume: number; // GB
}

export interface SpecialResourceRequirement {
  resourceType: 'fpga' | 'custom_accelerator' | 'high_memory_node' | 'infiniband';
  quantity: number;
  specifications: Record<string, any>;
  availability: 'required' | 'preferred' | 'optional';
}

export interface ResourceConstraint {
  constraintType: 'cost_limit' | 'time_limit' | 'energy_limit' | 'custom';
  constraintValue: number;
  constraintUnit: string;
  enforced: boolean;
  violationAction: 'stop' | 'warn' | 'scale_down' | 'ignore';
}

export interface ExecutionParameters {
  maxExecutionTime: number; // minutes
  checkpointingEnabled: boolean;
  checkpointInterval: number; // minutes
  loggingLevel: 'debug' | 'info' | 'warning' | 'error';
  environmentVariables: Record<string, string>;
  containerConfig?: ContainerConfig;
  distributedConfig?: DistributedExecutionConfig;
}

export interface ContainerConfig {
  containerImage: string;
  containerTag: string;
  registryCredentials?: RegistryCredentials;
  resourceLimits: ContainerResourceLimits;
  volumeMounts: VolumeMount[];
  securityContext: SecurityContext;
}

export interface RegistryCredentials {
  registryUrl: string;
  username: string;
  password: string;
  authToken?: string;
}

export interface ContainerResourceLimits {
  cpuLimit: string;
  memoryLimit: string;
  gpuLimit?: number;
  storageLimit?: string;
}

export interface VolumeMount {
  volumeName: string;
  mountPath: string;
  volumeType: 'persistent' | 'temporary' | 'config' | 'secret';
  readOnly: boolean;
  subPath?: string;
}

export interface SecurityContext {
  runAsUser?: number;
  runAsGroup?: number;
  fsGroup?: number;
  privileged: boolean;
  allowPrivilegeEscalation: boolean;
  readOnlyRootFilesystem: boolean;
}

export interface DistributedExecutionConfig {
  distributionStrategy: 'data_parallel' | 'model_parallel' | 'pipeline_parallel';
  workerCount: number;
  communicationBackend: 'nccl' | 'gloo' | 'mpi';
  masterWorkerConfig: MasterWorkerConfig;
  faultTolerance: DistributedFaultTolerance;
}

export interface MasterWorkerConfig {
  masterPort: number;
  workerPorts: number[];
  heartbeatInterval: number; // seconds
  syncTimeout: number; // seconds
}

export interface DistributedFaultTolerance {
  maxFailures: number;
  recoveryStrategy: 'restart' | 'continue' | 'checkpoint_restore';
  healthCheckInterval: number; // seconds
  elasticScaling: boolean;
}

export interface JobMonitoringConfig {
  monitoringEnabled: boolean;
  monitoringInterval: number; // seconds
  metricsCollection: MetricsCollection;
  alerting: JobAlerting;
  healthChecks: HealthCheck[];
  performanceProfiler?: PerformanceProfiler;
}

export interface MetricsCollection {
  systemMetrics: boolean;
  trainingMetrics: boolean;
  resourceMetrics: boolean;
  businessMetrics: boolean;
  customMetrics: CustomMetric[];
  aggregationWindow: number; // seconds
}

export interface CustomMetric {
  metricName: string;
  metricType: 'counter' | 'gauge' | 'histogram' | 'summary';
  collectionMethod: 'pull' | 'push' | 'calculated';
  collectionFrequency: number; // seconds
  metadata: Record<string, any>;
}

export interface JobAlerting {
  alertingEnabled: boolean;
  alertChannels: AlertChannel[];
  alertRules: JobAlertRule[];
  escalationPolicy: AlertEscalationPolicy;
}

export interface AlertChannel {
  channelType: 'email' | 'slack' | 'webhook' | 'pagerduty' | 'sms';
  channelConfig: Record<string, any>;
  severity: 'low' | 'medium' | 'high' | 'critical';
}

export interface JobAlertRule {
  ruleName: string;
  condition: string;
  threshold: number;
  evaluationWindow: number; // seconds
  severity: 'low' | 'medium' | 'high' | 'critical';
  alertFrequency: 'once' | 'recurring' | 'on_change';
}

export interface AlertEscalationPolicy {
  escalationEnabled: boolean;
  escalationSteps: EscalationStep[];
  escalationTimeout: number; // minutes
  autoResolution: boolean;
}

export interface EscalationStep {
  stepLevel: number;
  notificationTargets: string[];
  escalationDelay: number; // minutes
  actionRequired: boolean;
}

export interface HealthCheck {
  checkName: string;
  checkType: 'process' | 'http' | 'tcp' | 'metric' | 'custom';
  checkConfig: Record<string, any>;
  checkInterval: number; // seconds
  timeoutSeconds: number;
  failureThreshold: number;
  successThreshold: number;
}

export interface PerformanceProfiler {
  profilerEnabled: boolean;
  profilerType: 'cpu' | 'memory' | 'gpu' | 'network' | 'all';
  profilingInterval: number; // seconds
  profilingDuration: number; // minutes
  outputFormat: 'json' | 'flamegraph' | 'trace' | 'summary';
}

export interface JobRetryPolicy {
  retryEnabled: boolean;
  maxRetries: number;
  retryDelay: number; // minutes
  backoffStrategy: 'linear' | 'exponential' | 'fixed' | 'custom';
  retryConditions: RetryCondition[];
  giveUpConditions: GiveUpCondition[];
}

export interface RetryCondition {
  conditionType: 'exit_code' | 'error_pattern' | 'timeout' | 'resource_failure' | 'custom';
  conditionValue: any;
  retryable: boolean;
  delayMultiplier?: number;
}

export interface GiveUpCondition {
  conditionType: 'max_time_exceeded' | 'cost_exceeded' | 'persistent_failure' | 'manual_stop';
  conditionValue: any;
  finalAction: 'mark_failed' | 'mark_cancelled' | 'notify_admin';
}

export interface JobNotificationSettings {
  notificationEnabled: boolean;
  notificationEvents: NotificationEvent[];
  notificationChannels: NotificationChannel[];
  notificationTemplates: NotificationTemplate[];
}

export interface NotificationEvent {
  eventType: 'job_started' | 'job_completed' | 'job_failed' | 'job_cancelled' | 'milestone_reached' | 'custom';
  eventCondition?: string;
  notificationDelay?: number; // seconds
  includeLogs: boolean;
  includeMetrics: boolean;
}

export interface NotificationChannel {
  channelType: 'email' | 'slack' | 'teams' | 'webhook' | 'sms' | 'push';
  channelConfig: Record<string, any>;
  channelFilters: ChannelFilter[];
}

export interface ChannelFilter {
  filterType: 'severity' | 'job_type' | 'tenant' | 'tag' | 'custom';
  filterValue: any;
  includeFilter: boolean;
}

export interface NotificationTemplate {
  templateName: string;
  templateType: 'email' | 'slack' | 'webhook' | 'sms';
  templateContent: string;
  templateVariables: string[];
  templateLanguage: 'english' | 'indonesian' | 'auto';
}

export interface TrainingJobResult {
  jobId: string;
  request: TrainingJobRequest;
  jobExecution: JobExecutionResult;
  resourceUtilization: JobResourceUtilization;
  performanceMetrics: JobPerformanceMetrics;
  outputArtifacts: JobOutputArtifact[];
  executionLogs: ExecutionLog[];
  notifications: NotificationRecord[];
  metadata: JobMetadata;
}

export interface JobExecutionResult {
  executionId: string;
  status: JobStatus;
  startTime: Date;
  endTime?: Date;
  executionDuration?: number; // minutes
  exitCode?: number;
  errorMessage?: string;
  checkpoints: Checkpoint[];
  stageResults: JobStageResult[];
}

export type JobStatus = 
  | 'queued'
  | 'pending_resources'
  | 'starting'
  | 'running'
  | 'paused'
  | 'completed'
  | 'failed'
  | 'cancelled'
  | 'timeout'
  | 'preempted';

export interface Checkpoint {
  checkpointId: string;
  checkpointTime: Date;
  checkpointPath: string;
  checkpointSize: number;
  checkpointMetrics: Record<string, number>;
  checkpointMetadata: Record<string, any>;
}

export interface JobStageResult {
  stageId: string;
  stageName: string;
  stageStatus: JobStatus;
  stageStartTime: Date;
  stageEndTime?: Date;
  stageDuration?: number;
  stageMetrics: Record<string, number>;
  stageOutputs: StageOutput[];
  stageErrors?: StageError[];
}

export interface StageOutput {
  outputName: string;
  outputType: string;
  outputLocation: string;
  outputSize: number;
  outputChecksum?: string;
  outputMetadata: Record<string, any>;
}

export interface StageError {
  errorType: string;
  errorMessage: string;
  errorCode?: string;
  errorTime: Date;
  errorSeverity: 'low' | 'medium' | 'high' | 'critical';
  errorContext: Record<string, any>;
}

export interface JobResourceUtilization {
  overallUtilization: ResourceUtilizationSnapshot;
  utilizationHistory: ResourceUtilizationSnapshot[];
  peakUtilization: ResourceUtilizationSnapshot;
  averageUtilization: ResourceUtilizationSnapshot;
  resourceEfficiency: ResourceEfficiency;
  costAnalysis: JobCostAnalysis;
}

export interface ResourceUtilizationSnapshot {
  timestamp: Date;
  cpuUtilization: number;
  memoryUtilization: number;
  gpuUtilization?: number;
  storageUtilization: number;
  networkUtilization: number;
  customMetrics: Record<string, number>;
}

export interface ResourceEfficiency {
  overallEfficiency: number;
  cpuEfficiency: number;
  memoryEfficiency: number;
  gpuEfficiency?: number;
  storageEfficiency: number;
  networkEfficiency: number;
  wastedResources: WastedResource[];
}

export interface WastedResource {
  resourceType: string;
  wastedAmount: number;
  wastedPercentage: number;
  wasteReason: string;
  optimizationSuggestion: string;
}

export interface JobCostAnalysis {
  totalCost: number;
  costBreakdown: CostBreakdown;
  costEfficiency: number;
  budgetComparison: BudgetComparison;
  costOptimizations: CostOptimization[];
}

export interface CostBreakdown {
  computeCost: number;
  storageCost: number;
  networkCost: number;
  licenseCost: number;
  infrastructureCost: number;
  otherCosts: Record<string, number>;
}

export interface BudgetComparison {
  budgetAllocated: number;
  budgetUsed: number;
  budgetRemaining: number;
  budgetVariance: number;
  budgetUtilization: number;
}

export interface CostOptimization {
  optimizationType: string;
  currentCost: number;
  optimizedCost: number;
  potentialSavings: number;
  implementationEffort: 'low' | 'medium' | 'high';
  riskLevel: 'low' | 'medium' | 'high';
  recommendation: string;
}

export interface JobPerformanceMetrics {
  trainingMetrics: TrainingPerformanceMetrics;
  systemMetrics: SystemPerformanceMetrics;
  businessMetrics: BusinessPerformanceMetrics;
  qualityMetrics: QualityMetrics;
  benchmarkComparisons: BenchmarkComparison[];
}

export interface TrainingPerformanceMetrics {
  finalAccuracy: number;
  bestAccuracy: number;
  convergenceEpoch: number;
  trainingLoss: number[];
  validationLoss: number[];
  learningCurve: LearningCurvePoint[];
  overfittingScore: number;
}

export interface LearningCurvePoint {
  epoch: number;
  trainingScore: number;
  validationScore: number;
  timestamp: Date;
}

export interface SystemPerformanceMetrics {
  averageLatency: number;
  throughput: number;
  errorRate: number;
  uptime: number;
  systemStability: number;
  performanceVariability: number;
}

export interface BusinessPerformanceMetrics {
  businessValue: number;
  roiEstimate: number;
  timeToValue: number;
  businessImpactScore: number;
  userSatisfactionScore?: number;
  deploymentReadiness: number;
}

export interface QualityMetrics {
  modelQuality: number;
  dataQuality: number;
  codeQuality: number;
  documentationQuality: number;
  testCoverage: number;
  overallQuality: number;
}

export interface BenchmarkComparison {
  benchmarkName: string;
  benchmarkType: 'internal' | 'industry' | 'academic' | 'custom';
  ourPerformance: number;
  benchmarkPerformance: number;
  performanceRatio: number;
  ranking?: string;
  comparisonNotes: string;
}

export interface JobOutputArtifact {
  artifactId: string;
  artifactName: string;
  artifactType: 'model' | 'dataset' | 'plot' | 'report' | 'log' | 'checkpoint' | 'custom';
  artifactLocation: string;
  artifactSize: number;
  artifactFormat: string;
  artifactChecksum: string;
  artifactMetadata: ArtifactMetadata;
  accessPermissions: AccessPermission[];
}

export interface ArtifactMetadata {
  creationTime: Date;
  lastModified: Date;
  version: string;
  tags: Record<string, string>;
  description: string;
  provenance: ProvenanceInfo;
  qualityScore?: number;
}

export interface ProvenanceInfo {
  sourceJob: string;
  sourceStage: string;
  inputArtifacts: string[];
  transformations: string[];
  dataLineage: string[];
}

export interface AccessPermission {
  principalType: 'user' | 'group' | 'service_account' | 'role';
  principalId: string;
  permissions: string[];
  expirationTime?: Date;
}

export interface ExecutionLog {
  logId: string;
  logLevel: 'debug' | 'info' | 'warning' | 'error' | 'critical';
  logMessage: string;
  logTimestamp: Date;
  logSource: string;
  logContext: Record<string, any>;
  logStructured: boolean;
}

export interface NotificationRecord {
  notificationId: string;
  notificationType: string;
  notificationChannel: string;
  notificationTime: Date;
  notificationContent: string;
  notificationStatus: 'sent' | 'delivered' | 'failed' | 'pending';
  recipientInfo: Record<string, any>;
}

export interface JobMetadata {
  jobVersion: string;
  createdBy: string;
  createdTime: Date;
  lastModified: Date;
  modifiedBy: string;
  jobTags: Record<string, string>;
  parentJobs: string[];
  childJobs: string[];
  relatedJobs: string[];
  complianceInfo: JobComplianceInfo;
}

export interface JobComplianceInfo {
  dataPrivacyCompliant: boolean;
  securityCompliant: boolean;
  auditTrailComplete: boolean;
  regulatoryCompliant: boolean;
  complianceChecks: ComplianceCheck[];
  complianceScore: number;
}

export interface ComplianceCheck {
  checkType: string;
  checkStatus: 'passed' | 'failed' | 'warning' | 'not_applicable';
  checkDetails: string;
  checkTime: Date;
  checkResult: Record<string, any>;
}

@Injectable()
export class TrainingJobManagementService {
  private readonly logger = new Logger(TrainingJobManagementService.name);

  constructor(
    @InjectRepository(InventoryTransaction)
    private readonly inventoryTransactionRepository: Repository<InventoryTransaction>,
    
    @InjectRepository(Product)
    private readonly productRepository: Repository<Product>,
    
    @InjectRepository(MLModel)
    private readonly mlModelRepository: Repository<MLModel>,
    
    @InjectRepository(TrainingJob)
    private readonly trainingJobRepository: Repository<TrainingJob>,
    
    @Inject(CACHE_MANAGER)
    private readonly cacheManager: Cache,
    
    private readonly eventEmitter: EventEmitter2,
  ) {}

  async submitTrainingJob(request: TrainingJobRequest): Promise<TrainingJobResult> {
    this.logger.log(`Submitting training job for tenant: ${request.tenantId}`);
    const startTime = Date.now();
    
    try {
      // Validate job request
      await this.validateJobRequest(request);
      
      // Create job execution context
      const jobExecution = await this.createJobExecution(request);
      
      // Schedule job
      await this.scheduleJob(request, jobExecution);
      
      // Start job monitoring
      await this.startJobMonitoring(request, jobExecution);
      
      // Execute job (simplified for this implementation)
      const executionResult = await this.executeJob(request, jobExecution);
      
      // Collect job outputs
      const outputArtifacts = await this.collectJobOutputs(executionResult);
      
      // Generate performance metrics
      const performanceMetrics = await this.generatePerformanceMetrics(executionResult);
      
      // Calculate resource utilization
      const resourceUtilization = await this.calculateResourceUtilization(executionResult);
      
      const result: TrainingJobResult = {
        jobId: request.jobConfiguration.jobId,
        request,
        jobExecution: executionResult,
        resourceUtilization,
        performanceMetrics,
        outputArtifacts,
        executionLogs: this.generateExecutionLogs(executionResult),
        notifications: this.generateNotificationRecords(request),
        metadata: {
          jobVersion: '1.0',
          createdBy: 'system',
          createdTime: new Date(),
          lastModified: new Date(),
          modifiedBy: 'system',
          jobTags: request.jobConfiguration.tags,
          parentJobs: [],
          childJobs: [],
          relatedJobs: [],
          complianceInfo: {
            dataPrivacyCompliant: true,
            securityCompliant: true,
            auditTrailComplete: true,
            regulatoryCompliant: true,
            complianceChecks: [],
            complianceScore: 100
          }
        }
      };

      // Cache job result
      await this.cacheManager.set(
        `training_job_${request.jobConfiguration.jobId}`,
        result,
        7200 // 2 hours TTL
      );

      // Emit job completion event
      this.eventEmitter.emit('training.job.completed', {
        jobId: request.jobConfiguration.jobId,
        tenantId: request.tenantId,
        jobType: request.jobConfiguration.jobType,
        status: executionResult.status,
        executionTime: Date.now() - startTime,
        performanceScore: performanceMetrics.qualityMetrics.overallQuality
      });

      this.logger.log(`Training job completed: ${request.jobConfiguration.jobId} in ${Date.now() - startTime}ms`);
      return result;
      
    } catch (error) {
      this.logger.error(`Error in training job management: ${error.message}`, error.stack);
      throw new Error(`Training job submission failed: ${error.message}`);
    }
  }

  async getJobStatus(jobId: string, tenantId: string): Promise<JobExecutionResult> {
    const cachedResult = await this.cacheManager.get(`training_job_${jobId}`);
    if (cachedResult) {
      return (cachedResult as TrainingJobResult).jobExecution;
    }

    // Query from database
    const job = await this.trainingJobRepository.findOne({
      where: { id: jobId /* add tenant filter */ }
    });

    if (!job) {
      throw new Error(`Job not found: ${jobId}`);
    }

    return this.mapJobToExecutionResult(job);
  }

  async cancelJob(jobId: string, tenantId: string, reason?: string): Promise<boolean> {
    this.logger.log(`Cancelling job: ${jobId} for tenant: ${tenantId}`);
    
    try {
      // Update job status
      await this.updateJobStatus(jobId, 'cancelled');
      
      // Cleanup resources
      await this.cleanupJobResources(jobId);
      
      // Send notifications
      await this.sendCancellationNotifications(jobId, tenantId, reason);
      
      // Emit cancellation event
      this.eventEmitter.emit('training.job.cancelled', {
        jobId,
        tenantId,
        reason,
        timestamp: new Date()
      });

      return true;
    } catch (error) {
      this.logger.error(`Error cancelling job ${jobId}: ${error.message}`, error.stack);
      return false;
    }
  }

  async retryJob(jobId: string, tenantId: string): Promise<TrainingJobResult> {
    this.logger.log(`Retrying job: ${jobId} for tenant: ${tenantId}`);
    
    const originalJob = await this.getJobStatus(jobId, tenantId);
    
    // Create new job request based on original
    const retryRequest = await this.createRetryRequest(originalJob, tenantId);
    
    // Submit retry job
    return await this.submitTrainingJob(retryRequest);
  }

  // Private helper methods (simplified implementations)
  private async validateJobRequest(request: TrainingJobRequest): Promise<void> {
    if (!request.jobConfiguration.jobId) {
      throw new Error('Job ID is required');
    }
    
    if (!request.jobConfiguration.trainingPipelineId) {
      throw new Error('Training pipeline ID is required');
    }
    
    // Additional validation logic...
  }

  private async createJobExecution(request: TrainingJobRequest): Promise<JobExecutionResult> {
    return {
      executionId: `execution_${request.jobConfiguration.jobId}_${Date.now()}`,
      status: 'queued',
      startTime: new Date(),
      checkpoints: [],
      stageResults: []
    };
  }

  private async scheduleJob(request: TrainingJobRequest, jobExecution: JobExecutionResult): Promise<void> {
    // Implement job scheduling logic
    this.logger.log(`Job scheduled: ${request.jobConfiguration.jobId}`);
  }

  private async startJobMonitoring(request: TrainingJobRequest, jobExecution: JobExecutionResult): Promise<void> {
    // Implement job monitoring setup
    this.logger.log(`Job monitoring started: ${request.jobConfiguration.jobId}`);
  }

  private async executeJob(request: TrainingJobRequest, jobExecution: JobExecutionResult): Promise<JobExecutionResult> {
    // Simplified job execution
    return {
      ...jobExecution,
      status: 'completed',
      endTime: new Date(),
      executionDuration: 120, // 2 hours
      exitCode: 0,
      stageResults: this.generateStageResults(request)
    };
  }

  private generateStageResults(request: TrainingJobRequest): JobStageResult[] {
    return [
      {
        stageId: 'data_loading',
        stageName: 'Data Loading',
        stageStatus: 'completed',
        stageStartTime: new Date(),
        stageEndTime: new Date(),
        stageDuration: 10,
        stageMetrics: { 'records_loaded': 10000 },
        stageOutputs: [{
          outputName: 'loaded_data',
          outputType: 'dataset',
          outputLocation: '/data/loaded',
          outputSize: 1024000,
          outputMetadata: { 'record_count': 10000 }
        }]
      },
      {
        stageId: 'model_training',
        stageName: 'Model Training',
        stageStatus: 'completed',
        stageStartTime: new Date(),
        stageEndTime: new Date(),
        stageDuration: 100,
        stageMetrics: { 'final_accuracy': 0.87 },
        stageOutputs: [{
          outputName: 'trained_model',
          outputType: 'model',
          outputLocation: '/models/trained',
          outputSize: 50000000,
          outputMetadata: { 'accuracy': 0.87 }
        }]
      }
    ];
  }

  private async collectJobOutputs(executionResult: JobExecutionResult): Promise<JobOutputArtifact[]> {
    return executionResult.stageResults.flatMap(stage => 
      stage.stageOutputs.map(output => ({
        artifactId: `artifact_${output.outputName}`,
        artifactName: output.outputName,
        artifactType: output.outputType as any,
        artifactLocation: output.outputLocation,
        artifactSize: output.outputSize,
        artifactFormat: 'binary',
        artifactChecksum: 'sha256:placeholder',
        artifactMetadata: {
          creationTime: new Date(),
          lastModified: new Date(),
          version: '1.0',
          tags: {},
          description: output.outputName,
          provenance: {
            sourceJob: executionResult.executionId,
            sourceStage: stage.stageId,
            inputArtifacts: [],
            transformations: [],
            dataLineage: []
          }
        },
        accessPermissions: []
      }))
    );
  }

  private async generatePerformanceMetrics(executionResult: JobExecutionResult): Promise<JobPerformanceMetrics> {
    return {
      trainingMetrics: {
        finalAccuracy: 0.87,
        bestAccuracy: 0.89,
        convergenceEpoch: 85,
        trainingLoss: Array.from({ length: 100 }, (_, i) => 1 - (i * 0.009)),
        validationLoss: Array.from({ length: 100 }, (_, i) => 1 - (i * 0.008)),
        learningCurve: Array.from({ length: 100 }, (_, i) => ({
          epoch: i + 1,
          trainingScore: i * 0.008 + 0.2,
          validationScore: i * 0.0075 + 0.25,
          timestamp: new Date()
        })),
        overfittingScore: 0.15
      },
      systemMetrics: {
        averageLatency: 150,
        throughput: 1000,
        errorRate: 0.001,
        uptime: 0.999,
        systemStability: 0.95,
        performanceVariability: 0.05
      },
      businessMetrics: {
        businessValue: 150000,
        roiEstimate: 3.2,
        timeToValue: 30,
        businessImpactScore: 0.85,
        deploymentReadiness: 0.9
      },
      qualityMetrics: {
        modelQuality: 0.87,
        dataQuality: 0.92,
        codeQuality: 0.88,
        documentationQuality: 0.75,
        testCoverage: 0.82,
        overallQuality: 0.85
      },
      benchmarkComparisons: [{
        benchmarkName: 'Industry Standard',
        benchmarkType: 'industry',
        ourPerformance: 0.87,
        benchmarkPerformance: 0.82,
        performanceRatio: 1.06,
        ranking: 'Above Average',
        comparisonNotes: 'Performance exceeds industry standard'
      }]
    };
  }

  private async calculateResourceUtilization(executionResult: JobExecutionResult): Promise<JobResourceUtilization> {
    const currentSnapshot: ResourceUtilizationSnapshot = {
      timestamp: new Date(),
      cpuUtilization: 0.75,
      memoryUtilization: 0.68,
      gpuUtilization: 0.85,
      storageUtilization: 0.45,
      networkUtilization: 0.32,
      customMetrics: {}
    };

    return {
      overallUtilization: currentSnapshot,
      utilizationHistory: [currentSnapshot],
      peakUtilization: {
        ...currentSnapshot,
        cpuUtilization: 0.95,
        memoryUtilization: 0.87,
        gpuUtilization: 0.98
      },
      averageUtilization: currentSnapshot,
      resourceEfficiency: {
        overallEfficiency: 0.75,
        cpuEfficiency: 0.75,
        memoryEfficiency: 0.68,
        gpuEfficiency: 0.85,
        storageEfficiency: 0.45,
        networkEfficiency: 0.32,
        wastedResources: []
      },
      costAnalysis: {
        totalCost: 85.50,
        costBreakdown: {
          computeCost: 60.00,
          storageCost: 15.00,
          networkCost: 5.50,
          licenseCost: 3.00,
          infrastructureCost: 2.00,
          otherCosts: {}
        },
        costEfficiency: 0.78,
        budgetComparison: {
          budgetAllocated: 100.00,
          budgetUsed: 85.50,
          budgetRemaining: 14.50,
          budgetVariance: -14.50,
          budgetUtilization: 0.855
        },
        costOptimizations: []
      }
    };
  }

  private generateExecutionLogs(executionResult: JobExecutionResult): ExecutionLog[] {
    return [
      {
        logId: 'log_1',
        logLevel: 'info',
        logMessage: 'Job started successfully',
        logTimestamp: new Date(),
        logSource: 'job_manager',
        logContext: { jobId: executionResult.executionId },
        logStructured: true
      },
      {
        logId: 'log_2',
        logLevel: 'info',
        logMessage: 'Training completed with accuracy: 0.87',
        logTimestamp: new Date(),
        logSource: 'trainer',
        logContext: { accuracy: 0.87 },
        logStructured: true
      }
    ];
  }

  private generateNotificationRecords(request: TrainingJobRequest): NotificationRecord[] {
    if (!request.notificationSettings?.notificationEnabled) {
      return [];
    }

    return [
      {
        notificationId: 'notif_1',
        notificationType: 'job_completed',
        notificationChannel: 'email',
        notificationTime: new Date(),
        notificationContent: 'Your training job has completed successfully',
        notificationStatus: 'sent',
        recipientInfo: { tenant: request.tenantId }
      }
    ];
  }

  private mapJobToExecutionResult(job: TrainingJob): JobExecutionResult {
    return {
      executionId: job.id,
      status: 'completed', // Map from job status
      startTime: job.createdAt,
      endTime: job.updatedAt,
      executionDuration: 120,
      exitCode: 0,
      checkpoints: [],
      stageResults: []
    };
  }

  private async updateJobStatus(jobId: string, status: JobStatus): Promise<void> {
    // Update job status in database
    this.logger.log(`Updated job ${jobId} status to ${status}`);
  }

  private async cleanupJobResources(jobId: string): Promise<void> {
    // Cleanup allocated resources
    this.logger.log(`Cleaned up resources for job ${jobId}`);
  }

  private async sendCancellationNotifications(jobId: string, tenantId: string, reason?: string): Promise<void> {
    // Send cancellation notifications
    this.logger.log(`Sent cancellation notifications for job ${jobId}`);
  }

  private async createRetryRequest(originalJob: JobExecutionResult, tenantId: string): Promise<TrainingJobRequest> {
    // Create retry request from original job
    return {
      tenantId,
      jobConfiguration: {
        jobId: `retry_${originalJob.executionId}`,
        jobName: 'Retry Job',
        jobType: 'single_model_training',
        jobDescription: 'Retry of failed job',
        trainingPipelineId: 'pipeline_1',
        modelSpecifications: [],
        datasetReferences: [],
        dependencies: [],
        tags: { retry: 'true' }
      },
      schedulingOptions: {
        schedulingMode: 'immediate'
      },
      resourceRequirements: {
        computeResources: {
          cpuCores: 4,
          gpuRequired: true,
          computeIntensity: 'medium'
        },
        memoryRequirement: {
          ramRequired: 16,
          memoryType: 'standard',
          swapEnabled: false,
          memoryOptimization: 'balanced'
        },
        storageRequirement: {
          diskSpace: 100,
          storageType: 'ssd',
          iopsRequired: 1000,
          throughputRequired: 100,
          temporaryStorage: 50,
          persistentStorage: 50
        },
        networkRequirement: {
          bandwidthRequired: 100,
          latencyThreshold: 10,
          networkType: 'standard',
          externalAccess: true,
          dataTransferVolume: 10
        },
        resourceConstraints: []
      },
      executionParameters: {
        maxExecutionTime: 180,
        checkpointingEnabled: true,
        checkpointInterval: 30,
        loggingLevel: 'info',
        environmentVariables: {}
      },
      monitoringConfig: {
        monitoringEnabled: true,
        monitoringInterval: 60,
        metricsCollection: {
          systemMetrics: true,
          trainingMetrics: true,
          resourceMetrics: true,
          businessMetrics: false,
          customMetrics: [],
          aggregationWindow: 300
        },
        alerting: {
          alertingEnabled: true,
          alertChannels: [],
          alertRules: [],
          escalationPolicy: {
            escalationEnabled: false,
            escalationSteps: [],
            escalationTimeout: 60,
            autoResolution: true
          }
        },
        healthChecks: []
      },
      priorityLevel: 'medium'
    };
  }
}