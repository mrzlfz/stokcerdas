import { Injectable, Logger } from '@nestjs/common';
import { InjectRepository } from '@nestjs/typeorm';
import { Repository, Between, MoreThan, LessThan } from 'typeorm';
import { CACHE_MANAGER } from '@nestjs/cache-manager';
import { Inject } from '@nestjs/common';
import { Cache } from 'cache-manager';
import { EventEmitter2 } from '@nestjs/event-emitter';
import { Cron, CronExpression } from '@nestjs/schedule';
import * as moment from 'moment-timezone';
import { performance } from 'perf_hooks';

import {
  InventoryTransaction,
  TransactionType,
} from '../../inventory/entities/inventory-transaction.entity';
import { Product } from '../../products/entities/product.entity';
import { InventoryItem } from '../../inventory/entities/inventory-item.entity';

export interface TimeSeriesDataPoint {
  date: string;
  value: number;
  productId: string;
  locationId?: string;
  categoryId?: string;
  metadata?: Record<string, any>;
}

export interface FeatureSet {
  productFeatures: Record<string, any>;
  temporalFeatures: Record<string, any>;
  inventoryFeatures: Record<string, any>;
  externalFeatures?: Record<string, any>;
}

export interface DataPipelineConfig {
  dateRange: {
    from: string;
    to: string;
  };
  aggregation: 'daily' | 'weekly' | 'monthly';
  productIds?: string[];
  categoryIds?: string[];
  locationIds?: string[];
  includeExternalFactors?: boolean;
  features: string[];
  target: string;
  // Enhanced configuration options
  batchSize?: number;
  maxRetries?: number;
  priority?: 'low' | 'medium' | 'high';
  cacheTTL?: number;
  enableQualityChecks?: boolean;
  parallelProcessing?: boolean;
}

export interface DataPipelineJob {
  id: string;
  tenantId: string;
  type: 'extraction' | 'transformation' | 'validation' | 'training';
  status: 'pending' | 'running' | 'completed' | 'failed' | 'cancelled';
  config: DataPipelineConfig;
  progress: number;
  startTime?: Date;
  endTime?: Date;
  errorMessage?: string;
  retryCount: number;
  result?: any;
  metrics: {
    recordsProcessed: number;
    executionTimeMs: number;
    memoryUsageMB: number;
    cacheHitRatio: number;
  };
}

export interface DataQualityReport {
  jobId: string;
  tenantId: string;
  timestamp: Date;
  datasetInfo: {
    recordCount: number;
    dateRange: { from: string; to: string };
    productCount: number;
    completeness: number; // 0-1
  };
  qualityChecks: {
    missingValues: { field: string; percentage: number }[];
    outliers: { field: string; count: number; threshold: number }[];
    inconsistencies: { type: string; description: string; count: number }[];
    duplicates: { count: number; percentage: number };
  };
  scores: {
    overall: number; // 0-100
    completeness: number;
    accuracy: number;
    consistency: number;
    uniqueness: number;
  };
  recommendations: string[];
}

export interface ExternalDataSource {
  name: string;
  type: 'weather' | 'economic' | 'social' | 'competitor';
  endpoint: string;
  apiKey?: string;
  refreshInterval: number; // minutes
  enabled: boolean;
  lastUpdated?: Date;
  dataQuality?: number;
}

export interface PipelineMetrics {
  executionTime: number;
  memoryUsage: number;
  cacheHitRatio: number;
  errorRate: number;
  throughput: number; // records per second
  latency: number; // ms
}

@Injectable()
export class DataPipelineService {
  private readonly logger = new Logger(DataPipelineService.name);
  
  // Enhanced pipeline tracking and management
  private activeJobs = new Map<string, DataPipelineJob>();
  private jobQueue: DataPipelineJob[] = [];
  private maxConcurrentJobs = 3;
  private metricsHistory: Map<string, PipelineMetrics[]> = new Map();
  
  // External data sources configuration
  private externalDataSources: ExternalDataSource[] = [
    {
      name: 'Indonesian Weather Service',
      type: 'weather',
      endpoint: 'https://api.bmkg.go.id',
      refreshInterval: 60, // 1 hour
      enabled: true,
    },
    {
      name: 'Bank Indonesia Economic Data',
      type: 'economic',
      endpoint: 'https://api.bi.go.id',
      refreshInterval: 1440, // Daily
      enabled: true,
    },
    {
      name: 'Social Media Trends',
      type: 'social',
      endpoint: 'https://api.social-trends.com',
      refreshInterval: 240, // 4 hours
      enabled: false, // Disabled by default
    }
  ];

  constructor(
    @InjectRepository(InventoryTransaction)
    private inventoryTransactionRepo: Repository<InventoryTransaction>,

    @InjectRepository(Product)
    private productRepo: Repository<Product>,

    @InjectRepository(InventoryItem)
    private inventoryItemRepo: Repository<InventoryItem>,

    @Inject(CACHE_MANAGER)
    private cacheManager: Cache,
    
    private eventEmitter: EventEmitter2,
  ) {
    // Initialize pipeline monitoring
    this.setupPipelineMonitoring();
  }

  /**
   * PHASE 2.2.1: Enhanced Pipeline Architecture - Job Management System
   */

  /**
   * Create and queue a new data pipeline job
   */
  async createPipelineJob(
    tenantId: string,
    type: DataPipelineJob['type'],
    config: DataPipelineConfig,
  ): Promise<string> {
    const jobId = `${type}_${tenantId}_${Date.now()}`;
    
    const job: DataPipelineJob = {
      id: jobId,
      tenantId,
      type,
      status: 'pending',
      config: {
        batchSize: 1000,
        maxRetries: 3,
        priority: 'medium',
        cacheTTL: 3600,
        enableQualityChecks: true,
        parallelProcessing: false,
        ...config
      },
      progress: 0,
      retryCount: 0,
      metrics: {
        recordsProcessed: 0,
        executionTimeMs: 0,
        memoryUsageMB: 0,
        cacheHitRatio: 0,
      },
    };

    // Add to queue based on priority
    this.addJobToQueue(job);
    
    // Emit job created event
    this.eventEmitter.emit('pipeline.job.created', { jobId, tenantId, type });
    
    this.logger.log(`Created pipeline job ${jobId} for tenant ${tenantId}`);
    
    // Process queue if not at capacity
    this.processJobQueue();
    
    return jobId;
  }

  /**
   * Get job status and progress
   */
  async getJobStatus(jobId: string): Promise<DataPipelineJob | null> {
    return this.activeJobs.get(jobId) || 
           this.jobQueue.find(job => job.id === jobId) || 
           null;
  }

  /**
   * Cancel a running or queued job
   */
  async cancelJob(jobId: string): Promise<boolean> {
    const job = this.activeJobs.get(jobId);
    if (job) {
      job.status = 'cancelled';
      this.activeJobs.delete(jobId);
      this.eventEmitter.emit('pipeline.job.cancelled', { jobId });
      return true;
    }

    // Remove from queue if pending
    const queueIndex = this.jobQueue.findIndex(j => j.id === jobId);
    if (queueIndex >= 0) {
      this.jobQueue[queueIndex].status = 'cancelled';
      this.jobQueue.splice(queueIndex, 1);
      this.eventEmitter.emit('pipeline.job.cancelled', { jobId });
      return true;
    }

    return false;
  }

  /**
   * Get pipeline performance metrics
   */
  async getPipelineMetrics(tenantId?: string): Promise<{
    activeJobs: number;
    queuedJobs: number;
    completedJobs24h: number;
    errorRate: number;
    avgExecutionTime: number;
    memoryUsage: number;
  }> {
    const now = Date.now();
    const last24h = now - (24 * 60 * 60 * 1000);

    let activeJobs = 0;
    let queuedJobs = 0;
    let totalExecutionTime = 0;
    let totalMemoryUsage = 0;
    let errorCount = 0;
    let completedCount = 0;

    // Count active jobs
    for (const job of this.activeJobs.values()) {
      if (!tenantId || job.tenantId === tenantId) {
        if (job.status === 'running') activeJobs++;
      }
    }

    // Count queued jobs
    queuedJobs = this.jobQueue.filter(job => 
      job.status === 'pending' && (!tenantId || job.tenantId === tenantId)
    ).length;

    // Calculate metrics from history
    for (const [id, metricsList] of this.metricsHistory.entries()) {
      if (tenantId && !id.includes(tenantId)) continue;
      
      const recentMetrics = metricsList.filter(m => 
        (now - m.executionTime) < last24h
      );

      for (const metrics of recentMetrics) {
        totalExecutionTime += metrics.executionTime;
        totalMemoryUsage += metrics.memoryUsage;
        if (metrics.errorRate > 0) errorCount++;
        completedCount++;
      }
    }

    return {
      activeJobs,
      queuedJobs,
      completedJobs24h: completedCount,
      errorRate: completedCount > 0 ? errorCount / completedCount : 0,
      avgExecutionTime: completedCount > 0 ? totalExecutionTime / completedCount : 0,
      memoryUsage: completedCount > 0 ? totalMemoryUsage / completedCount : 0,
    };
  }

  /**
   * Enhanced data quality validation system
   */
  async validateDataQuality(
    timeSeries: TimeSeriesDataPoint[],
    tenantId: string,
    jobId: string,
  ): Promise<DataQualityReport> {
    const startTime = performance.now();
    
    this.logger.debug(`Running data quality validation for job ${jobId}`);

    const report: DataQualityReport = {
      jobId,
      tenantId,
      timestamp: new Date(),
      datasetInfo: {
        recordCount: timeSeries.length,
        dateRange: {
          from: timeSeries.length > 0 ? timeSeries[0].date : '',
          to: timeSeries.length > 0 ? timeSeries[timeSeries.length - 1].date : '',
        },
        productCount: new Set(timeSeries.map(ts => ts.productId)).size,
        completeness: 0,
      },
      qualityChecks: {
        missingValues: [],
        outliers: [],
        inconsistencies: [],
        duplicates: { count: 0, percentage: 0 },
      },
      scores: {
        overall: 0,
        completeness: 0,
        accuracy: 0,
        consistency: 0,
        uniqueness: 0,
      },
      recommendations: [],
    };

    if (timeSeries.length === 0) {
      report.recommendations.push('No data available for analysis');
      return report;
    }

    // 1. Check for missing values
    const missingValueChecks = await this.checkMissingValues(timeSeries);
    report.qualityChecks.missingValues = missingValueChecks;

    // 2. Detect outliers using statistical methods
    const outlierChecks = await this.detectOutliers(timeSeries);
    report.qualityChecks.outliers = outlierChecks;

    // 3. Check for data inconsistencies
    const inconsistencyChecks = await this.checkDataInconsistencies(timeSeries);
    report.qualityChecks.inconsistencies = inconsistencyChecks;

    // 4. Identify duplicates
    const duplicateCheck = await this.checkDuplicates(timeSeries);
    report.qualityChecks.duplicates = duplicateCheck;

    // 5. Calculate quality scores
    report.scores = await this.calculateQualityScores(report.qualityChecks, timeSeries);
    report.scores.overall = (
      report.scores.completeness +
      report.scores.accuracy +
      report.scores.consistency +
      report.scores.uniqueness
    ) / 4;

    // 6. Generate recommendations
    report.recommendations = await this.generateQualityRecommendations(report);

    // Log execution time
    const executionTime = performance.now() - startTime;
    this.logger.debug(`Data quality validation completed in ${executionTime.toFixed(2)}ms`);

    // Emit quality report event
    this.eventEmitter.emit('pipeline.quality.report', { 
      jobId, 
      tenantId, 
      score: report.scores.overall 
    });

    return report;
  }

  /**
   * Multi-level caching system with intelligent invalidation
   */
  async getFromCache<T>(
    key: string,
    fetchFunction: () => Promise<T>,
    ttl: number = 3600,
    enableMultiLevel: boolean = true,
  ): Promise<T> {
    // Level 1: In-memory cache (fastest)
    const memoryKey = `memory:${key}`;
    let result = await this.cacheManager.get<T>(memoryKey);
    
    if (result) {
      this.updateCacheMetrics(key, 'memory_hit');
      return result;
    }

    // Level 2: Redis cache (medium speed)
    const redisKey = `redis:${key}`;
    result = await this.cacheManager.get<T>(redisKey);
    
    if (result && enableMultiLevel) {
      // Store in memory for faster access
      await this.cacheManager.set(memoryKey, result, Math.min(ttl, 300)); // Max 5 min in memory
      this.updateCacheMetrics(key, 'redis_hit');
      return result;
    }

    // Level 3: Fetch from source
    this.logger.debug(`Cache miss for key: ${key}, fetching from source`);
    result = await fetchFunction();
    
    // Store in all cache levels
    if (enableMultiLevel) {
      await Promise.all([
        this.cacheManager.set(memoryKey, result, Math.min(ttl, 300)),
        this.cacheManager.set(redisKey, result, ttl),
      ]);
    } else {
      await this.cacheManager.set(key, result, ttl);
    }
    
    this.updateCacheMetrics(key, 'cache_miss');
    return result;
  }

  /**
   * Intelligent cache invalidation based on data dependencies
   */
  async invalidateRelatedCaches(
    entityType: 'product' | 'transaction' | 'inventory',
    entityId: string,
    tenantId: string,
  ): Promise<void> {
    const patterns = this.getCacheInvalidationPatterns(entityType, entityId, tenantId);
    
    for (const pattern of patterns) {
      await this.cacheManager.del(pattern);
      this.logger.debug(`Invalidated cache pattern: ${pattern}`);
    }

    // Emit cache invalidation event
    this.eventEmitter.emit('pipeline.cache.invalidated', {
      entityType,
      entityId,
      tenantId,
      patterns,
    });
  }

  /**
   * Batch processing with parallel execution
   */
  async processBatch<T, R>(
    items: T[],
    processor: (item: T) => Promise<R>,
    batchSize: number = 100,
    maxConcurrency: number = 5,
  ): Promise<R[]> {
    const results: R[] = [];
    const batches = this.createBatches(items, batchSize);
    
    this.logger.debug(`Processing ${items.length} items in ${batches.length} batches`);

    for (const batch of batches) {
      const batchPromises = batch.map(item => processor(item));
      const batchResults = await Promise.allSettled(batchPromises);
      
      for (const result of batchResults) {
        if (result.status === 'fulfilled') {
          results.push(result.value);
        } else {
          this.logger.error(`Batch processing error: ${result.reason}`);
        }
      }
    }

    return results;
  }

  /**
   * Scheduled job for pipeline maintenance and optimization
   */
  @Cron(CronExpression.EVERY_HOUR)
  async performPipelineMaintenance(): Promise<void> {
    this.logger.debug('Starting pipeline maintenance tasks');

    try {
      // 1. Clean up completed jobs older than 24 hours
      await this.cleanupOldJobs();

      // 2. Update external data sources
      await this.refreshExternalDataSources();

      // 3. Optimize cache usage
      await this.optimizeCacheUsage();

      // 4. Generate performance reports
      await this.generatePerformanceReport();

      // 5. Health check on pipeline components
      await this.performHealthCheck();

    } catch (error) {
      this.logger.error(`Pipeline maintenance failed: ${error.message}`, error.stack);
    }
  }

  /**
   * Real-time streaming data processor
   */
  async processStreamingData(
    tenantId: string,
    dataStream: AsyncIterable<TimeSeriesDataPoint>,
    config: DataPipelineConfig,
  ): Promise<void> {
    const jobId = await this.createPipelineJob(tenantId, 'extraction', config);
    const job = this.activeJobs.get(jobId)!;
    
    job.status = 'running';
    job.startTime = new Date();

    try {
      let processedCount = 0;
      const batchBuffer: TimeSeriesDataPoint[] = [];
      const batchSize = config.batchSize || 1000;

      for await (const dataPoint of dataStream) {
        batchBuffer.push(dataPoint);
        processedCount++;

        // Update job progress
        job.progress = Math.min(95, (processedCount / (config.batchSize || 10000)) * 100);

        // Process batch when buffer is full
        if (batchBuffer.length >= batchSize) {
          await this.processBatchData(batchBuffer, tenantId, jobId);
          batchBuffer.length = 0; // Clear buffer
        }

        // Emit progress event
        if (processedCount % 100 === 0) {
          this.eventEmitter.emit('pipeline.progress', {
            jobId,
            tenantId,
            progress: job.progress,
            recordsProcessed: processedCount,
          });
        }
      }

      // Process remaining data in buffer
      if (batchBuffer.length > 0) {
        await this.processBatchData(batchBuffer, tenantId, jobId);
      }

      // Complete job
      job.status = 'completed';
      job.endTime = new Date();
      job.progress = 100;
      job.metrics.recordsProcessed = processedCount;
      job.metrics.executionTimeMs = job.endTime.getTime() - job.startTime.getTime();

      this.eventEmitter.emit('pipeline.job.completed', { jobId, tenantId });

    } catch (error) {
      job.status = 'failed';
      job.errorMessage = error.message;
      job.endTime = new Date();
      
      this.logger.error(`Streaming data processing failed: ${error.message}`, error.stack);
      this.eventEmitter.emit('pipeline.job.failed', { jobId, tenantId, error: error.message });
    }
  }

  /**
   * Extract historical sales data for time series analysis
   * Enhanced with new architecture features
   */
  async extractSalesData(
    tenantId: string,
    config: DataPipelineConfig,
  ): Promise<TimeSeriesDataPoint[]> {
    this.logger.debug(`Extracting sales data for tenant ${tenantId}`);

    const cacheKey = `sales_data_${tenantId}_${JSON.stringify(config)}`;
    const cached = await this.cacheManager.get<TimeSeriesDataPoint[]>(cacheKey);

    if (cached) {
      this.logger.debug('Returning cached sales data');
      return cached;
    }

    const queryBuilder = this.inventoryTransactionRepo
      .createQueryBuilder('transaction')
      .leftJoinAndSelect('transaction.product', 'product')
      .where('transaction.tenantId = :tenantId', { tenantId })
      .andWhere('transaction.type = :saleType', {
        saleType: TransactionType.SALE,
      })
      .andWhere('transaction.transactionDate BETWEEN :from AND :to', {
        from: config.dateRange.from,
        to: config.dateRange.to,
      })
      .andWhere('transaction.status = :status', { status: 'completed' });

    if (config.productIds?.length) {
      queryBuilder.andWhere('transaction.productId IN (:...productIds)', {
        productIds: config.productIds,
      });
    }

    if (config.categoryIds?.length) {
      queryBuilder.andWhere('product.categoryId IN (:...categoryIds)', {
        categoryIds: config.categoryIds,
      });
    }

    if (config.locationIds?.length) {
      queryBuilder.andWhere('transaction.locationId IN (:...locationIds)', {
        locationIds: config.locationIds,
      });
    }

    const transactions = await queryBuilder
      .orderBy('transaction.transactionDate', 'ASC')
      .getMany();

    const timeSeries = this.aggregateTransactionData(
      transactions,
      config.aggregation,
    );

    // Cache for 1 hour
    await this.cacheManager.set(cacheKey, timeSeries, 3600);

    this.logger.debug(`Extracted ${timeSeries.length} data points`);
    return timeSeries;
  }

  /**
   * Extract product features for ML models
   */
  async extractProductFeatures(
    tenantId: string,
    productIds: string[],
  ): Promise<Record<string, FeatureSet>> {
    this.logger.debug(`Extracting features for ${productIds.length} products`);

    const products = await this.productRepo.find({
      where: {
        tenantId,
        id: productIds.length ? ({ $in: productIds } as any) : undefined,
      },
      relations: ['category', 'inventoryItems'],
    });

    const features: Record<string, FeatureSet> = {};

    for (const product of products) {
      features[product.id] = await this.extractSingleProductFeatures(
        tenantId,
        product,
      );
    }

    return features;
  }

  /**
   * Extract temporal features (seasonality, trends, etc.)
   */
  async extractTemporalFeatures(
    timeSeries: TimeSeriesDataPoint[],
    aggregation: 'daily' | 'weekly' | 'monthly',
  ): Promise<Record<string, any>> {
    this.logger.debug('Extracting temporal features');

    if (timeSeries.length === 0) {
      return {};
    }

    const features: Record<string, any> = {};

    // Sort by date
    const sortedData = timeSeries.sort(
      (a, b) => new Date(a.date).getTime() - new Date(b.date).getTime(),
    );

    // Basic statistics
    const values = sortedData.map(d => d.value);
    features.mean = this.calculateMean(values);
    features.std = this.calculateStandardDeviation(values);
    features.min = Math.min(...values);
    features.max = Math.max(...values);
    features.median = this.calculateMedian(values);

    // Trend analysis
    features.trend = this.calculateTrend(sortedData);

    // Seasonality analysis
    const seasonality = this.calculateSeasonality(sortedData, aggregation);
    features.seasonality = seasonality;

    // Autocorrelation
    features.autocorrelation = this.calculateAutocorrelation(
      values,
      [1, 7, 30],
    );

    // Volatility
    features.volatility = this.calculateVolatility(values);

    // Growth rate
    features.growthRate = this.calculateGrowthRate(values);

    return features;
  }

  /**
   * Preprocess data for ML models
   */
  async preprocessData(
    timeSeries: TimeSeriesDataPoint[],
    features: Record<string, FeatureSet>,
    config: DataPipelineConfig,
  ): Promise<{
    features: number[][];
    target: number[];
    featureNames: string[];
    dates: string[];
  }> {
    this.logger.debug('Preprocessing data for ML training');

    const processedData = {
      features: [] as number[][],
      target: [] as number[],
      featureNames: [] as string[],
      dates: [] as string[],
    };

    // Group time series by product
    const productTimeSeries = this.groupTimeSeriesByProduct(timeSeries);

    for (const [productId, productData] of Object.entries(productTimeSeries)) {
      const productFeatures = features[productId];
      if (!productFeatures) continue;

      // Create feature matrix for this product
      const productFeatureMatrix = this.createFeatureMatrix(
        productData,
        productFeatures,
        config.features,
      );

      processedData.features.push(...productFeatureMatrix.features);
      processedData.target.push(...productFeatureMatrix.target);
      processedData.dates.push(...productFeatureMatrix.dates);

      // Store feature names (only once)
      if (processedData.featureNames.length === 0) {
        processedData.featureNames = productFeatureMatrix.featureNames;
      }
    }

    // Handle missing values
    this.handleMissingValues(processedData.features);

    // Normalize features if needed
    if (config.features.includes('normalize')) {
      this.normalizeFeatures(processedData.features);
    }

    this.logger.debug(
      `Preprocessed data: ${processedData.features.length} samples, ${processedData.featureNames.length} features`,
    );

    return processedData;
  }

  /**
   * Create training and validation sets
   */
  createTrainValidationSplit(
    features: number[][],
    target: number[],
    dates: string[],
    splitRatio: number = 0.8,
    method: 'time_series' | 'random' = 'time_series',
  ): {
    train: { features: number[][]; target: number[]; dates: string[] };
    validation: { features: number[][]; target: number[]; dates: string[] };
  } {
    this.logger.debug(
      `Creating train/validation split with ratio ${splitRatio}`,
    );

    const totalSamples = features.length;
    const trainSize = Math.floor(totalSamples * splitRatio);

    if (method === 'time_series') {
      // For time series, split by time to avoid data leakage
      return {
        train: {
          features: features.slice(0, trainSize),
          target: target.slice(0, trainSize),
          dates: dates.slice(0, trainSize),
        },
        validation: {
          features: features.slice(trainSize),
          target: target.slice(trainSize),
          dates: dates.slice(trainSize),
        },
      };
    } else {
      // Random split
      const indices = Array.from({ length: totalSamples }, (_, i) => i);
      this.shuffleArray(indices);

      const trainIndices = indices.slice(0, trainSize);
      const validationIndices = indices.slice(trainSize);

      return {
        train: {
          features: trainIndices.map(i => features[i]),
          target: trainIndices.map(i => target[i]),
          dates: trainIndices.map(i => dates[i]),
        },
        validation: {
          features: validationIndices.map(i => features[i]),
          target: validationIndices.map(i => target[i]),
          dates: validationIndices.map(i => dates[i]),
        },
      };
    }
  }

  /**
   * Get external factors (holidays, weather, etc.)
   */
  async getExternalFactors(
    dateRange: { from: string; to: string },
    tenantId: string,
  ): Promise<Record<string, any>> {
    this.logger.debug('Getting external factors');

    const factors: Record<string, any> = {};

    // Indonesian holidays and events
    factors.holidays = this.getIndonesianHolidays(dateRange);

    // Ramadan and religious periods
    factors.religiousPeriods = this.getReligiousPeriods(dateRange);

    // Economic indicators (placeholder - would integrate with external APIs)
    factors.economicIndicators = this.getEconomicIndicators(dateRange);

    // Payday cycles (common in Indonesia: 25th and 10th)
    factors.paydayCycles = this.getPaydayCycles(dateRange);

    return factors;
  }

  // Private helper methods

  private aggregateTransactionData(
    transactions: InventoryTransaction[],
    aggregation: 'daily' | 'weekly' | 'monthly',
  ): TimeSeriesDataPoint[] {
    const aggregated: Record<string, Record<string, number>> = {};

    for (const transaction of transactions) {
      const dateKey = this.getDateKey(transaction.transactionDate, aggregation);
      const productKey = transaction.productId;

      if (!aggregated[dateKey]) {
        aggregated[dateKey] = {};
      }

      if (!aggregated[dateKey][productKey]) {
        aggregated[dateKey][productKey] = 0;
      }

      aggregated[dateKey][productKey] += Math.abs(transaction.quantity);
    }

    const timeSeries: TimeSeriesDataPoint[] = [];

    for (const [date, products] of Object.entries(aggregated)) {
      for (const [productId, value] of Object.entries(products)) {
        timeSeries.push({
          date,
          value,
          productId,
          locationId: transactions.find(t => t.productId === productId)?.locationId,
          categoryId: transactions.find(t => t.productId === productId)?.product?.categoryId,
          metadata: {
            aggregation,
            transactionCount: transactions.filter(
              t => this.getDateKey(t.transactionDate, aggregation) === date && t.productId === productId
            ).length,
          },
        });
      }
    }

    return timeSeries.sort((a, b) => new Date(a.date).getTime() - new Date(b.date).getTime());
  }

  // ========== PHASE 2.2.1: MISSING HELPER METHODS IMPLEMENTATION ==========

  /**
   * Initialize pipeline monitoring system
   */
  private setupPipelineMonitoring(): void {
    this.logger.debug('Setting up pipeline monitoring system');
    
    // Initialize metrics collection
    this.eventEmitter.on('pipeline.*', (data) => {
      this.collectMetrics(data);
    });

    // Setup periodic metric collection
    setInterval(() => {
      this.collectSystemMetrics();
    }, 30000); // Every 30 seconds
  }

  /**
   * Add job to queue with priority ordering
   */
  private addJobToQueue(job: DataPipelineJob): void {
    const priorityOrder = { high: 3, medium: 2, low: 1 };
    const jobPriority = priorityOrder[job.config.priority || 'medium'];
    
    // Insert job in priority order
    let insertIndex = this.jobQueue.length;
    for (let i = 0; i < this.jobQueue.length; i++) {
      const existingPriority = priorityOrder[this.jobQueue[i].config.priority || 'medium'];
      if (jobPriority > existingPriority) {
        insertIndex = i;
        break;
      }
    }
    
    this.jobQueue.splice(insertIndex, 0, job);
    this.logger.debug(`Job ${job.id} added to queue at position ${insertIndex}`);
  }

  /**
   * Process queued jobs
   */
  private async processJobQueue(): Promise<void> {
    if (this.activeJobs.size >= this.maxConcurrentJobs || this.jobQueue.length === 0) {
      return;
    }

    const job = this.jobQueue.shift();
    if (!job) return;

    job.status = 'running';
    job.startTime = new Date();
    this.activeJobs.set(job.id, job);

    try {
      await this.executeJob(job);
    } catch (error) {
      this.logger.error(`Job ${job.id} failed: ${error.message}`);
      job.status = 'failed';
      job.errorMessage = error.message;
    } finally {
      job.endTime = new Date();
      this.activeJobs.delete(job.id);
      
      // Try to process next job
      this.processJobQueue();
    }
  }

  /**
   * Execute a data pipeline job
   */
  private async executeJob(job: DataPipelineJob): Promise<void> {
    this.logger.debug(`Executing job ${job.id} of type ${job.type}`);

    switch (job.type) {
      case 'extraction':
        job.result = await this.extractSalesData(job.tenantId, job.config);
        break;
      case 'transformation':
        // Implement transformation logic
        break;
      case 'validation':
        // Implement validation logic
        break;
      case 'training':
        // Implement training logic
        break;
      default:
        throw new Error(`Unknown job type: ${job.type}`);
    }

    job.status = 'completed';
    job.progress = 100;
  }

  /**
   * Check for missing values in time series data
   */
  private async checkMissingValues(
    timeSeries: TimeSeriesDataPoint[]
  ): Promise<{ field: string; percentage: number }[]> {
    const checks = [];
    
    // Check for missing dates
    const expectedDates = this.generateExpectedDates(
      timeSeries[0]?.date || new Date().toISOString(),
      timeSeries[timeSeries.length - 1]?.date || new Date().toISOString(),
      'daily'
    );
    
    const actualDates = new Set(timeSeries.map(ts => ts.date));
    const missingDates = expectedDates.filter(date => !actualDates.has(date));
    
    checks.push({
      field: 'date',
      percentage: (missingDates.length / expectedDates.length) * 100
    });

    // Check for missing values
    const nullValues = timeSeries.filter(ts => ts.value == null || isNaN(ts.value));
    checks.push({
      field: 'value',
      percentage: (nullValues.length / timeSeries.length) * 100
    });

    // Check for missing product IDs
    const missingProductIds = timeSeries.filter(ts => !ts.productId);
    checks.push({
      field: 'productId',
      percentage: (missingProductIds.length / timeSeries.length) * 100
    });

    return checks;
  }

  /**
   * Detect outliers using statistical methods
   */
  private async detectOutliers(
    timeSeries: TimeSeriesDataPoint[]
  ): Promise<{ field: string; count: number; threshold: number }[]> {
    const values = timeSeries.map(ts => ts.value).filter(v => v != null && !isNaN(v));
    
    if (values.length === 0) {
      return [];
    }

    const mean = this.calculateMean(values);
    const std = this.calculateStandardDeviation(values);
    const threshold = 3 * std; // 3-sigma rule
    
    const outliers = values.filter(v => Math.abs(v - mean) > threshold);
    
    return [{
      field: 'value',
      count: outliers.length,
      threshold
    }];
  }

  /**
   * Check for data inconsistencies
   */
  private async checkDataInconsistencies(
    timeSeries: TimeSeriesDataPoint[]
  ): Promise<{ type: string; description: string; count: number }[]> {
    const inconsistencies = [];

    // Check for negative values (unusual for sales)
    const negativeValues = timeSeries.filter(ts => ts.value < 0);
    if (negativeValues.length > 0) {
      inconsistencies.push({
        type: 'negative_values',
        description: 'Found negative sales values',
        count: negativeValues.length
      });
    }

    // Check for extremely high values
    const values = timeSeries.map(ts => ts.value);
    const q99 = this.calculatePercentile(values, 99);
    const extremeValues = timeSeries.filter(ts => ts.value > q99 * 10);
    
    if (extremeValues.length > 0) {
      inconsistencies.push({
        type: 'extreme_values',
        description: 'Found extremely high values',
        count: extremeValues.length
      });
    }

    // Check for date ordering issues
    let dateOrderIssues = 0;
    for (let i = 1; i < timeSeries.length; i++) {
      if (new Date(timeSeries[i].date) < new Date(timeSeries[i-1].date)) {
        dateOrderIssues++;
      }
    }
    
    if (dateOrderIssues > 0) {
      inconsistencies.push({
        type: 'date_ordering',
        description: 'Found date ordering issues',
        count: dateOrderIssues
      });
    }

    return inconsistencies;
  }

  /**
   * Check for duplicate records
   */
  private async checkDuplicates(
    timeSeries: TimeSeriesDataPoint[]
  ): Promise<{ count: number; percentage: number }> {
    const seen = new Set<string>();
    let duplicates = 0;

    for (const ts of timeSeries) {
      const key = `${ts.date}_${ts.productId}_${ts.locationId || 'null'}`;
      if (seen.has(key)) {
        duplicates++;
      } else {
        seen.add(key);
      }
    }

    return {
      count: duplicates,
      percentage: (duplicates / timeSeries.length) * 100
    };
  }

  /**
   * Calculate data quality scores
   */
  private async calculateQualityScores(
    qualityChecks: DataQualityReport['qualityChecks'],
    timeSeries: TimeSeriesDataPoint[]
  ): Promise<DataQualityReport['scores']> {
    
    // Completeness score (100 - missing percentage)
    const avgMissingPercentage = qualityChecks.missingValues.reduce(
      (sum, check) => sum + check.percentage, 0
    ) / Math.max(qualityChecks.missingValues.length, 1);
    const completeness = Math.max(0, 100 - avgMissingPercentage);

    // Accuracy score (100 - outlier percentage)
    const totalOutliers = qualityChecks.outliers.reduce(
      (sum, check) => sum + check.count, 0
    );
    const accuracy = Math.max(0, 100 - (totalOutliers / timeSeries.length) * 100);

    // Consistency score (100 - inconsistency percentage)
    const totalInconsistencies = qualityChecks.inconsistencies.reduce(
      (sum, check) => sum + check.count, 0
    );
    const consistency = Math.max(0, 100 - (totalInconsistencies / timeSeries.length) * 100);

    // Uniqueness score (100 - duplicate percentage)
    const uniqueness = Math.max(0, 100 - qualityChecks.duplicates.percentage);

    return {
      overall: 0, // Will be calculated by caller
      completeness,
      accuracy,
      consistency,
      uniqueness
    };
  }

  /**
   * Generate quality improvement recommendations
   */
  private async generateQualityRecommendations(
    report: DataQualityReport
  ): Promise<string[]> {
    const recommendations = [];

    if (report.scores.completeness < 80) {
      recommendations.push('Improve data collection processes to reduce missing values');
    }

    if (report.scores.accuracy < 80) {
      recommendations.push('Review data entry processes to reduce outliers and errors');
    }

    if (report.scores.consistency < 80) {
      recommendations.push('Implement data validation rules to improve consistency');
    }

    if (report.scores.uniqueness < 90) {
      recommendations.push('Add unique constraints to prevent duplicate records');
    }

    if (report.scores.overall < 70) {
      recommendations.push('Consider data cleansing and enrichment processes');
    }

    return recommendations;
  }

  /**
   * Update cache performance metrics
   */
  private updateCacheMetrics(key: string, type: 'memory_hit' | 'redis_hit' | 'cache_miss'): void {
    // Implementation for cache metrics tracking
    const now = Date.now();
    const metricsKey = `cache_metrics_${key.split(':')[0]}`;
    
    // Emit cache event for monitoring
    this.eventEmitter.emit('pipeline.cache.access', {
      key,
      type,
      timestamp: now
    });
  }

  /**
   * Get cache invalidation patterns based on entity type
   */
  private getCacheInvalidationPatterns(
    entityType: 'product' | 'transaction' | 'inventory',
    entityId: string,
    tenantId: string
  ): string[] {
    const patterns = [];
    
    switch (entityType) {
      case 'product':
        patterns.push(`sales_data_${tenantId}_*${entityId}*`);
        patterns.push(`product_features_${tenantId}_${entityId}`);
        break;
      case 'transaction':
        patterns.push(`sales_data_${tenantId}_*`);
        patterns.push(`temporal_features_${tenantId}_*`);
        break;
      case 'inventory':
        patterns.push(`inventory_features_${tenantId}_${entityId}`);
        break;
    }
    
    return patterns;
  }

  /**
   * Create batches from array of items
   */
  private createBatches<T>(items: T[], batchSize: number): T[][] {
    const batches: T[][] = [];
    for (let i = 0; i < items.length; i += batchSize) {
      batches.push(items.slice(i, i + batchSize));
    }
    return batches;
  }

  /**
   * Process batch of streaming data
   */
  private async processBatchData(
    batch: TimeSeriesDataPoint[],
    tenantId: string,
    jobId: string
  ): Promise<void> {
    // Validate batch quality
    if (batch.length > 0) {
      const qualityReport = await this.validateDataQuality(batch, tenantId, jobId);
      
      if (qualityReport.scores.overall < 50) {
        this.logger.warn(`Low quality batch detected for job ${jobId}: ${qualityReport.scores.overall}`);
      }
    }
    
    // Process the batch (placeholder for actual processing logic)
    await new Promise(resolve => setTimeout(resolve, 10)); // Simulate processing
  }

  /**
   * Clean up old completed jobs
   */
  private async cleanupOldJobs(): Promise<void> {
    const cutoffTime = Date.now() - (24 * 60 * 60 * 1000); // 24 hours ago
    
    // Remove old metrics
    for (const [key, metricsList] of this.metricsHistory.entries()) {
      const filteredMetrics = metricsList.filter(
        m => (Date.now() - m.executionTime) < cutoffTime
      );
      this.metricsHistory.set(key, filteredMetrics);
    }
    
    this.logger.debug('Cleaned up old job metrics');
  }

  /**
   * Refresh external data sources
   */
  private async refreshExternalDataSources(): Promise<void> {
    for (const source of this.externalDataSources) {
      if (!source.enabled) continue;
      
      const lastUpdate = source.lastUpdated?.getTime() || 0;
      const now = Date.now();
      const shouldRefresh = (now - lastUpdate) > (source.refreshInterval * 60 * 1000);
      
      if (shouldRefresh) {
        try {
          // Placeholder for actual external API calls
          await this.fetchExternalData(source);
          source.lastUpdated = new Date();
          this.logger.debug(`Refreshed external data source: ${source.name}`);
        } catch (error) {
          this.logger.error(`Failed to refresh ${source.name}: ${error.message}`);
        }
      }
    }
  }

  /**
   * Optimize cache usage
   */
  private async optimizeCacheUsage(): Promise<void> {
    // Clear least recently used cache entries
    // This is a placeholder - actual implementation would depend on cache manager capabilities
    this.logger.debug('Optimizing cache usage');
  }

  /**
   * Generate performance report
   */
  private async generatePerformanceReport(): Promise<void> {
    const metrics = await this.getPipelineMetrics();
    
    this.logger.log(`Pipeline Performance Report:
` +
      `Active Jobs: ${metrics.activeJobs}
` +
      `Queued Jobs: ${metrics.queuedJobs}
` +
      `Completed (24h): ${metrics.completedJobs24h}
` +
      `Error Rate: ${(metrics.errorRate * 100).toFixed(2)}%
` +
      `Avg Execution Time: ${metrics.avgExecutionTime.toFixed(2)}ms
` +
      `Memory Usage: ${metrics.memoryUsage.toFixed(2)}MB`);
  }

  /**
   * Perform health check on pipeline components
   */
  private async performHealthCheck(): Promise<void> {
    const checks = {
      database: await this.checkDatabaseHealth(),
      cache: await this.checkCacheHealth(),
      external: await this.checkExternalSourcesHealth()
    };
    
    const allHealthy = Object.values(checks).every(health => health);
    
    if (!allHealthy) {
      this.logger.warn('Pipeline health check failed', checks);
      this.eventEmitter.emit('pipeline.health.warning', checks);
    }
  }

  // ========== STATISTICAL CALCULATION METHODS ==========

  /**
   * Extract features for a single product
   */
  private async extractSingleProductFeatures(
    tenantId: string,
    product: Product
  ): Promise<FeatureSet> {
    const features: FeatureSet = {
      productFeatures: {
        price: product.price || 0,
        costPrice: product.costPrice || 0,
        categoryId: product.categoryId,
        hasVariants: (product as any).variants?.length > 0,
        brand: product.brand || 'unknown',
        weight: product.weight || 0,
        dimensions: {
          length: product.length || 0,
          width: product.width || 0,
          height: product.height || 0
        }
      },
      temporalFeatures: {},
      inventoryFeatures: {
        totalStock: product.inventoryItems?.reduce((sum, item) => sum + item.quantityOnHand, 0) || 0,
        locationCount: product.inventoryItems?.length || 0,
        averageStock: product.inventoryItems?.length ?
          product.inventoryItems.reduce((sum, item) => sum + item.quantityOnHand, 0) / product.inventoryItems.length : 0
      },
      externalFeatures: {}
    };

    return features;
  }

  /**
   * Calculate mean of array
   */
  private calculateMean(values: number[]): number {
    if (values.length === 0) return 0;
    return values.reduce((sum, val) => sum + val, 0) / values.length;
  }

  /**
   * Calculate standard deviation
   */
  private calculateStandardDeviation(values: number[]): number {
    if (values.length === 0) return 0;
    const mean = this.calculateMean(values);
    const squaredDiffs = values.map(val => Math.pow(val - mean, 2));
    return Math.sqrt(this.calculateMean(squaredDiffs));
  }

  /**
   * Calculate median of array
   */
  private calculateMedian(values: number[]): number {
    if (values.length === 0) return 0;
    const sorted = [...values].sort((a, b) => a - b);
    const mid = Math.floor(sorted.length / 2);
    return sorted.length % 2 === 0 ?
      (sorted[mid - 1] + sorted[mid]) / 2 :
      sorted[mid];
  }

  /**
   * Calculate percentile
   */
  private calculatePercentile(values: number[], percentile: number): number {
    if (values.length === 0) return 0;
    const sorted = [...values].sort((a, b) => a - b);
    const index = (percentile / 100) * (sorted.length - 1);
    const lower = Math.floor(index);
    const upper = Math.ceil(index);
    const weight = index - lower;
    return sorted[lower] * (1 - weight) + sorted[upper] * weight;
  }

  /**
   * Calculate trend from time series
   */
  private calculateTrend(timeSeries: TimeSeriesDataPoint[]): number {
    if (timeSeries.length < 2) return 0;
    
    const values = timeSeries.map(ts => ts.value);
    const n = values.length;
    const x = Array.from({length: n}, (_, i) => i);
    
    // Simple linear regression for trend
    const sumX = x.reduce((a, b) => a + b, 0);
    const sumY = values.reduce((a, b) => a + b, 0);
    const sumXY = x.reduce((sum, xi, i) => sum + xi * values[i], 0);
    const sumXX = x.reduce((sum, xi) => sum + xi * xi, 0);
    
    const slope = (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);
    return slope;
  }

  /**
   * Calculate seasonality patterns
   */
  private calculateSeasonality(
    timeSeries: TimeSeriesDataPoint[],
    aggregation: 'daily' | 'weekly' | 'monthly'
  ): Record<string, number> {
    const seasonality: Record<string, number[]> = {};
    
    for (const ts of timeSeries) {
      const date = new Date(ts.date);
      let key: string;
      
      switch (aggregation) {
        case 'daily':
          key = date.getDay().toString(); // Day of week
          break;
        case 'weekly':
          key = Math.floor(date.getDate() / 7).toString(); // Week of month
          break;
        case 'monthly':
          key = date.getMonth().toString(); // Month of year
          break;
      }
      
      if (!seasonality[key]) {
        seasonality[key] = [];
      }
      seasonality[key].push(ts.value);
    }
    
    // Calculate average for each period
    const result: Record<string, number> = {};
    for (const [key, values] of Object.entries(seasonality)) {
      result[key] = this.calculateMean(values);
    }
    
    return result;
  }

  /**
   * Calculate autocorrelation
   */
  private calculateAutocorrelation(values: number[], lags: number[]): Record<number, number> {
    const result: Record<number, number> = {};
    const mean = this.calculateMean(values);
    
    for (const lag of lags) {
      if (lag >= values.length) {
        result[lag] = 0;
        continue;
      }
      
      let numerator = 0;
      let denominator = 0;
      
      for (let i = 0; i < values.length - lag; i++) {
        numerator += (values[i] - mean) * (values[i + lag] - mean);
      }
      
      for (let i = 0; i < values.length; i++) {
        denominator += Math.pow(values[i] - mean, 2);
      }
      
      result[lag] = denominator === 0 ? 0 : numerator / denominator;
    }
    
    return result;
  }

  /**
   * Calculate volatility
   */
  private calculateVolatility(values: number[]): number {
    if (values.length < 2) return 0;
    
    const returns = [];
    for (let i = 1; i < values.length; i++) {
      if (values[i - 1] !== 0) {
        returns.push((values[i] - values[i - 1]) / values[i - 1]);
      }
    }
    
    return this.calculateStandardDeviation(returns);
  }

  /**
   * Calculate growth rate
   */
  private calculateGrowthRate(values: number[]): number {
    if (values.length < 2) return 0;
    
    const firstValue = values[0] || 1;
    const lastValue = values[values.length - 1] || 0;
    
    return firstValue === 0 ? 0 : (lastValue - firstValue) / firstValue;
  }

  // ========== UTILITY METHODS ==========

  /**
   * Get date key for aggregation
   */
  private getDateKey(date: Date, aggregation: 'daily' | 'weekly' | 'monthly'): string {
    const d = new Date(date);
    
    switch (aggregation) {
      case 'daily':
        return d.toISOString().split('T')[0];
      case 'weekly':
        const year = d.getFullYear();
        const week = this.getWeekNumber(d);
        return `${year}-W${week.toString().padStart(2, '0')}`;
      case 'monthly':
        return `${d.getFullYear()}-${(d.getMonth() + 1).toString().padStart(2, '0')}`;
    }
  }

  /**
   * Get week number of year
   */
  private getWeekNumber(date: Date): number {
    const d = new Date(Date.UTC(date.getFullYear(), date.getMonth(), date.getDate()));
    const dayNum = d.getUTCDay() || 7;
    d.setUTCDate(d.getUTCDate() + 4 - dayNum);
    const yearStart = new Date(Date.UTC(d.getUTCFullYear(), 0, 1));
    return Math.ceil(((d.getTime() - yearStart.getTime()) / 86400000 + 1) / 7);
  }

  /**
   * Generate expected dates for completeness check
   */
  private generateExpectedDates(
    startDate: string,
    endDate: string,
    frequency: 'daily' | 'weekly' | 'monthly'
  ): string[] {
    const dates = [];
    const start = new Date(startDate);
    const end = new Date(endDate);
    const current = new Date(start);
    
    while (current <= end) {
      dates.push(this.getDateKey(current, frequency));
      
      switch (frequency) {
        case 'daily':
          current.setDate(current.getDate() + 1);
          break;
        case 'weekly':
          current.setDate(current.getDate() + 7);
          break;
        case 'monthly':
          current.setMonth(current.getMonth() + 1);
          break;
      }
    }
    
    return dates;
  }

  /**
   * Shuffle array in place
   */
  private shuffleArray<T>(array: T[]): void {
    for (let i = array.length - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [array[i], array[j]] = [array[j], array[i]];
    }
  }

  /**
   * Group time series by product
   */
  private groupTimeSeriesByProduct(
    timeSeries: TimeSeriesDataPoint[]
  ): Record<string, TimeSeriesDataPoint[]> {
    const grouped: Record<string, TimeSeriesDataPoint[]> = {};
    
    for (const ts of timeSeries) {
      if (!grouped[ts.productId]) {
        grouped[ts.productId] = [];
      }
      grouped[ts.productId].push(ts);
    }
    
    return grouped;
  }

  /**
   * Create feature matrix for ML training
   */
  private createFeatureMatrix(
    timeSeries: TimeSeriesDataPoint[],
    productFeatures: FeatureSet,
    requestedFeatures: string[]
  ): {
    features: number[][];
    target: number[];
    dates: string[];
    featureNames: string[];
  } {
    const features: number[][] = [];
    const target: number[] = [];
    const dates: string[] = [];
    const featureNames: string[] = ['price', 'cost', 'stock', 'trend', 'seasonality'];
    
    for (const ts of timeSeries) {
      const featureRow = [
        productFeatures.productFeatures.price || 0,
        productFeatures.productFeatures.costPrice || 0,
        productFeatures.inventoryFeatures.totalStock || 0,
        // Add more features as needed
        0, // trend placeholder
        0, // seasonality placeholder
      ];
      
      features.push(featureRow);
      target.push(ts.value);
      dates.push(ts.date);
    }
    
    return { features, target, dates, featureNames };
  }

  /**
   * Handle missing values in feature matrix
   */
  private handleMissingValues(features: number[][]): void {
    if (features.length === 0) return;
    
    const numFeatures = features[0].length;
    
    for (let col = 0; col < numFeatures; col++) {
      const columnValues = features.map(row => row[col]).filter(val => !isNaN(val));
      const mean = this.calculateMean(columnValues);
      
      for (let row = 0; row < features.length; row++) {
        if (isNaN(features[row][col])) {
          features[row][col] = mean;
        }
      }
    }
  }

  /**
   * Normalize features to 0-1 range
   */
  private normalizeFeatures(features: number[][]): void {
    if (features.length === 0) return;
    
    const numFeatures = features[0].length;
    
    for (let col = 0; col < numFeatures; col++) {
      const columnValues = features.map(row => row[col]);
      const min = Math.min(...columnValues);
      const max = Math.max(...columnValues);
      const range = max - min;
      
      if (range > 0) {
        for (let row = 0; row < features.length; row++) {
          features[row][col] = (features[row][col] - min) / range;
        }
      }
    }
  }

  // ========== INDONESIAN CONTEXT METHODS ==========

  /**
   * Get Indonesian holidays for date range
   */
  private getIndonesianHolidays(dateRange: { from: string; to: string }): any[] {
    // This would contain Indonesian holidays calendar
    return [
      { name: 'Ramadan', date: '2025-03-10', type: 'religious' },
      { name: 'Lebaran', date: '2025-04-10', type: 'religious' },
      { name: 'Independence Day', date: '2025-08-17', type: 'national' },
      { name: 'Christmas', date: '2025-12-25', type: 'religious' },
    ];
  }

  /**
   * Get religious periods affecting sales
   */
  private getReligiousPeriods(dateRange: { from: string; to: string }): any[] {
    return [
      { name: 'Ramadan Fasting', start: '2025-03-10', end: '2025-04-09', effect: 'decrease_day_increase_night' },
      { name: 'Christmas Season', start: '2025-12-01', end: '2025-12-31', effect: 'increase' },
    ];
  }

  /**
   * Get economic indicators
   */
  private getEconomicIndicators(dateRange: { from: string; to: string }): any {
    // Placeholder for BI (Bank Indonesia) API integration
    return {
      inflation: 3.2,
      gdpGrowth: 5.1,
      exchangeRate: 15800, // IDR/USD
      interestRate: 6.0
    };
  }

  /**
   * Get payday cycles (common in Indonesia)
   */
  private getPaydayCycles(dateRange: { from: string; to: string }): any[] {
    const cycles = [];
    const start = new Date(dateRange.from);
    const end = new Date(dateRange.to);
    const current = new Date(start);
    
    while (current <= end) {
      // 25th of each month (salary)
      cycles.push({
        date: new Date(current.getFullYear(), current.getMonth(), 25).toISOString().split('T')[0],
        type: 'salary',
        effect: 'increase'
      });
      
      // 10th of each month (bonus/allowance)
      cycles.push({
        date: new Date(current.getFullYear(), current.getMonth(), 10).toISOString().split('T')[0],
        type: 'allowance',
        effect: 'moderate_increase'
      });
      
      current.setMonth(current.getMonth() + 1);
    }
    
    return cycles;
  }

  // ========== HEALTH CHECK METHODS ==========

  /**
   * Check database connectivity
   */
  private async checkDatabaseHealth(): Promise<boolean> {
    try {
      await this.productRepo.count({ take: 1 });
      return true;
    } catch (error) {
      this.logger.error('Database health check failed', error);
      return false;
    }
  }

  /**
   * Check cache connectivity
   */
  private async checkCacheHealth(): Promise<boolean> {
    try {
      await this.cacheManager.set('health_check', 'ok', 10);
      const result = await this.cacheManager.get('health_check');
      return result === 'ok';
    } catch (error) {
      this.logger.error('Cache health check failed', error);
      return false;
    }
  }

  /**
   * Check external data sources health
   */
  private async checkExternalSourcesHealth(): Promise<boolean> {
    let allHealthy = true;
    
    for (const source of this.externalDataSources) {
      if (!source.enabled) continue;
      
      try {
        // Simple ping to check if endpoint is reachable
        // This is a placeholder - actual implementation would depend on API
        await Promise.resolve(true);
      } catch (error) {
        this.logger.error(`External source ${source.name} health check failed`, error);
        allHealthy = false;
      }
    }
    
    return allHealthy;
  }

  /**
   * Fetch data from external source
   */
  private async fetchExternalData(source: ExternalDataSource): Promise<any> {
    // Placeholder for actual external API integration
    this.logger.debug(`Fetching data from ${source.name}`);
    return { status: 'ok', lastUpdate: new Date() };
  }

  /**
   * Collect performance metrics
   */
  private collectMetrics(data: any): void {
    // Store metrics for analysis
    const timestamp = Date.now();
    // Implementation would store metrics in appropriate data structure
  }

  /**
   * Collect system metrics
   */
  private collectSystemMetrics(): void {
    const memUsage = process.memoryUsage();
    const metrics: PipelineMetrics = {
      executionTime: Date.now(),
      memoryUsage: memUsage.heapUsed / 1024 / 1024, // MB
      cacheHitRatio: 0, // Would be calculated from cache events
      errorRate: 0, // Would be calculated from error events
      throughput: 0, // Would be calculated from processing events
      latency: 0 // Would be calculated from timing events
    };
    
    // Store system metrics
    if (!this.metricsHistory.has('system')) {
      this.metricsHistory.set('system', []);
    }
    this.metricsHistory.get('system')!.push(metrics);
  }

    for (const transaction of transactions) {
      const date = this.getAggregationKey(
        transaction.transactionDate,
        aggregation,
      );
      const productId = transaction.productId;

      if (!aggregated[date]) {
        aggregated[date] = {};
      }

      if (!aggregated[date][productId]) {
        aggregated[date][productId] = 0;
      }

      aggregated[date][productId] += Math.abs(transaction.quantity);
    }

    const result: TimeSeriesDataPoint[] = [];

    for (const [date, products] of Object.entries(aggregated)) {
      for (const [productId, value] of Object.entries(products)) {
        result.push({
          date,
          value,
          productId,
          metadata: { aggregation },
        });
      }
    }

    return result;
  }

  private async extractSingleProductFeatures(
    tenantId: string,
    product: Product,
  ): Promise<FeatureSet> {
    const productFeatures: Record<string, any> = {
      // Price features
      costPrice: product.costPrice,
      sellingPrice: product.sellingPrice,
      profitMargin: product.profitMargin,

      // Product characteristics
      hasVariants: product.hasVariants,
      trackStock: product.trackStock,
      allowBackorder: product.allowBackorder,
      minStock: product.minStock,
      maxStock: product.maxStock,
      reorderPoint: product.reorderPoint,

      // Historical performance
      salesCount: product.salesCount,
      totalRevenue: product.totalRevenue,
      viewCount: product.viewCount,

      // Category features
      categoryId: product.categoryId || 'unknown',
      brand: product.brand || 'unknown',
      unit: product.unit || 'pcs',

      // Time features
      daysSinceCreated: moment().diff(moment(product.createdAt), 'days'),
      daysSinceLastSold: product.lastSoldAt
        ? moment().diff(moment(product.lastSoldAt), 'days')
        : 0,
    };

    // Get current inventory levels
    const inventoryFeatures = await this.getInventoryFeatures(
      tenantId,
      product.id,
    );

    return {
      productFeatures,
      temporalFeatures: {},
      inventoryFeatures,
    };
  }

  private async getInventoryFeatures(
    tenantId: string,
    productId: string,
  ): Promise<Record<string, any>> {
    const inventoryItems = await this.inventoryItemRepo.find({
      where: { tenantId, productId },
    });

    const totalStock = inventoryItems.reduce(
      (sum, item) => sum + item.quantityOnHand,
      0,
    );
    const totalReserved = inventoryItems.reduce(
      (sum, item) => sum + item.quantityReserved,
      0,
    );
    const totalValue = inventoryItems.reduce(
      (sum, item) => sum + item.totalValue,
      0,
    );

    return {
      totalStock,
      totalReserved,
      totalValue,
      stockLocations: inventoryItems.length,
      averageCost: totalStock > 0 ? totalValue / totalStock : 0,
      stockoutLocations: inventoryItems.filter(item => item.quantityOnHand <= 0)
        .length,
      lowStockLocations: inventoryItems.filter(item => item.isLowStock).length,
    };
  }

  private getAggregationKey(
    date: Date,
    aggregation: 'daily' | 'weekly' | 'monthly',
  ): string {
    const momentDate = moment(date).tz('Asia/Jakarta');

    switch (aggregation) {
      case 'daily':
        return momentDate.format('YYYY-MM-DD');
      case 'weekly':
        return momentDate.startOf('week').format('YYYY-MM-DD');
      case 'monthly':
        return momentDate.format('YYYY-MM');
      default:
        return momentDate.format('YYYY-MM-DD');
    }
  }

  private groupTimeSeriesByProduct(
    timeSeries: TimeSeriesDataPoint[],
  ): Record<string, TimeSeriesDataPoint[]> {
    const grouped: Record<string, TimeSeriesDataPoint[]> = {};

    for (const point of timeSeries) {
      if (!grouped[point.productId]) {
        grouped[point.productId] = [];
      }
      grouped[point.productId].push(point);
    }

    return grouped;
  }

  private createFeatureMatrix(
    timeSeries: TimeSeriesDataPoint[],
    productFeatures: FeatureSet,
    requestedFeatures: string[],
  ): {
    features: number[][];
    target: number[];
    featureNames: string[];
    dates: string[];
  } {
    const features: number[][] = [];
    const target: number[] = [];
    const dates: string[] = [];
    const featureNames: string[] = [];

    // Create feature names
    Object.keys(productFeatures.productFeatures).forEach(key => {
      featureNames.push(`product_${key}`);
    });
    Object.keys(productFeatures.inventoryFeatures).forEach(key => {
      featureNames.push(`inventory_${key}`);
    });

    // Add temporal features
    featureNames.push(
      'day_of_week',
      'day_of_month',
      'month',
      'quarter',
      'is_weekend',
    );

    // Create feature matrix
    for (const point of timeSeries) {
      const featureRow: number[] = [];

      // Product features
      Object.values(productFeatures.productFeatures).forEach(value => {
        featureRow.push(typeof value === 'number' ? value : 0);
      });

      // Inventory features
      Object.values(productFeatures.inventoryFeatures).forEach(value => {
        featureRow.push(typeof value === 'number' ? value : 0);
      });

      // Temporal features
      const momentDate = moment(point.date);
      featureRow.push(momentDate.day()); // day of week
      featureRow.push(momentDate.date()); // day of month
      featureRow.push(momentDate.month() + 1); // month
      featureRow.push(momentDate.quarter()); // quarter
      featureRow.push(momentDate.day() === 0 || momentDate.day() === 6 ? 1 : 0); // is weekend

      features.push(featureRow);
      target.push(point.value);
      dates.push(point.date);
    }

    return { features, target, featureNames, dates };
  }

  // Statistical helper methods
  private calculateMean(values: number[]): number {
    return values.reduce((sum, val) => sum + val, 0) / values.length;
  }

  private calculateStandardDeviation(values: number[]): number {
    const mean = this.calculateMean(values);
    const squaredDiffs = values.map(val => Math.pow(val - mean, 2));
    return Math.sqrt(this.calculateMean(squaredDiffs));
  }

  private calculateMedian(values: number[]): number {
    const sorted = [...values].sort((a, b) => a - b);
    const mid = Math.floor(sorted.length / 2);
    return sorted.length % 2 === 0
      ? (sorted[mid - 1] + sorted[mid]) / 2
      : sorted[mid];
  }

  private calculateTrend(data: TimeSeriesDataPoint[]): number {
    if (data.length < 2) return 0;

    // Simple linear trend calculation
    const n = data.length;
    const sumX = data.reduce((sum, _, index) => sum + index, 0);
    const sumY = data.reduce((sum, point) => sum + point.value, 0);
    const sumXY = data.reduce(
      (sum, point, index) => sum + index * point.value,
      0,
    );
    const sumXX = data.reduce((sum, _, index) => sum + index * index, 0);

    return (n * sumXY - sumX * sumY) / (n * sumXX - sumX * sumX);
  }

  private calculateSeasonality(
    data: TimeSeriesDataPoint[],
    aggregation: 'daily' | 'weekly' | 'monthly',
  ): Record<string, number> {
    const seasonality: Record<string, number[]> = {};

    for (const point of data) {
      const momentDate = moment(point.date);
      let key: string;

      switch (aggregation) {
        case 'daily':
          key = momentDate.format('dddd'); // Day of week
          break;
        case 'weekly':
          key = `week_${momentDate.week()}`;
          break;
        case 'monthly':
          key = momentDate.format('MMMM'); // Month name
          break;
        default:
          key = momentDate.format('dddd');
      }

      if (!seasonality[key]) {
        seasonality[key] = [];
      }
      seasonality[key].push(point.value);
    }

    // Calculate average for each seasonal component
    const result: Record<string, number> = {};
    for (const [key, values] of Object.entries(seasonality)) {
      result[key] = this.calculateMean(values);
    }

    return result;
  }

  private calculateAutocorrelation(
    values: number[],
    lags: number[],
  ): Record<string, number> {
    const result: Record<string, number> = {};
    const n = values.length;
    const mean = this.calculateMean(values);

    for (const lag of lags) {
      if (lag >= n) {
        result[`lag_${lag}`] = 0;
        continue;
      }

      let numerator = 0;
      let denominator = 0;

      for (let i = 0; i < n - lag; i++) {
        numerator += (values[i] - mean) * (values[i + lag] - mean);
      }

      for (let i = 0; i < n; i++) {
        denominator += Math.pow(values[i] - mean, 2);
      }

      result[`lag_${lag}`] = denominator !== 0 ? numerator / denominator : 0;
    }

    return result;
  }

  private calculateVolatility(values: number[]): number {
    if (values.length < 2) return 0;

    const returns = [];
    for (let i = 1; i < values.length; i++) {
      if (values[i - 1] !== 0) {
        returns.push((values[i] - values[i - 1]) / values[i - 1]);
      }
    }

    return this.calculateStandardDeviation(returns);
  }

  private calculateGrowthRate(values: number[]): number {
    if (values.length < 2) return 0;

    const firstValue = values[0];
    const lastValue = values[values.length - 1];
    const periods = values.length - 1;

    if (firstValue <= 0) return 0;

    return Math.pow(lastValue / firstValue, 1 / periods) - 1;
  }

  private handleMissingValues(features: number[][]): void {
    // Simple imputation with column means
    if (features.length === 0) return;

    const numFeatures = features[0].length;
    const columnMeans = new Array(numFeatures).fill(0);

    // Calculate means for each column
    for (let col = 0; col < numFeatures; col++) {
      let sum = 0;
      let count = 0;

      for (let row = 0; row < features.length; row++) {
        if (!isNaN(features[row][col]) && isFinite(features[row][col])) {
          sum += features[row][col];
          count++;
        }
      }

      columnMeans[col] = count > 0 ? sum / count : 0;
    }

    // Replace missing values with column means
    for (let row = 0; row < features.length; row++) {
      for (let col = 0; col < numFeatures; col++) {
        if (isNaN(features[row][col]) || !isFinite(features[row][col])) {
          features[row][col] = columnMeans[col];
        }
      }
    }
  }

  private normalizeFeatures(features: number[][]): void {
    if (features.length === 0) return;

    const numFeatures = features[0].length;

    for (let col = 0; col < numFeatures; col++) {
      const values = features.map(row => row[col]);
      const min = Math.min(...values);
      const max = Math.max(...values);
      const range = max - min;

      if (range === 0) continue;

      for (let row = 0; row < features.length; row++) {
        features[row][col] = (features[row][col] - min) / range;
      }
    }
  }

  private shuffleArray<T>(array: T[]): void {
    for (let i = array.length - 1; i > 0; i--) {
      const j = Math.floor(Math.random() * (i + 1));
      [array[i], array[j]] = [array[j], array[i]];
    }
  }

  // Indonesian-specific external factors
  private getIndonesianHolidays(dateRange: {
    from: string;
    to: string;
  }): Record<string, boolean> {
    const holidays: Record<string, boolean> = {};

    // Major Indonesian holidays (simplified)
    const holidayDates = [
      '01-01', // New Year
      '08-17', // Independence Day
      '12-25', // Christmas
      // Add more holidays based on calendar
    ];

    const startYear = new Date(dateRange.from).getFullYear();
    const endYear = new Date(dateRange.to).getFullYear();

    for (let year = startYear; year <= endYear; year++) {
      for (const holiday of holidayDates) {
        const date = `${year}-${holiday}`;
        if (date >= dateRange.from && date <= dateRange.to) {
          holidays[date] = true;
        }
      }
    }

    return holidays;
  }

  private getReligiousPeriods(dateRange: {
    from: string;
    to: string;
  }): Record<string, string> {
    // Simplified - would need proper Islamic calendar integration
    return {};
  }

  private getEconomicIndicators(dateRange: {
    from: string;
    to: string;
  }): Record<string, number> {
    // Placeholder - would integrate with external economic data APIs
    return {
      inflationRate: 3.5,
      gdpGrowth: 5.2,
      unemploymentRate: 6.1,
    };
  }

  private getPaydayCycles(dateRange: {
    from: string;
    to: string;
  }): Record<string, boolean> {
    const paydayCycles: Record<string, boolean> = {};

    const start = moment(dateRange.from);
    const end = moment(dateRange.to);

    const current = start.clone();

    while (current.isSameOrBefore(end)) {
      const day = current.date();

      // Common payday cycles in Indonesia: 25th and 10th
      if (day === 25 || day === 10) {
        paydayCycles[current.format('YYYY-MM-DD')] = true;
      }

      current.add(1, 'day');
    }

    return paydayCycles;
  }
}
